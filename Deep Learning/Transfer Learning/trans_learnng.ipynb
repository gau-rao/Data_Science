{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         path  label\n",
       "0  imagesv/v/o/h/voh71d00/509132755+-2755.tif      3\n",
       "1        imagesl/l/x/t/lxt19d00/502213303.tif      3\n",
       "2       imagesx/x/e/d/xed05a00/2075325674.tif      2\n",
       "3  imageso/o/j/b/ojb60d00/517511301+-1301.tif      3\n",
       "4       imagesq/q/z/k/qzk17e00/2031320195.tif      7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "df=pd.read_csv(\"labels_final.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33600 non-validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(validation_split=0.3,rescale=1./255)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=df,directory=\"./rvl-cdip/data_final/\",x_col=\"path\"\n",
    "                                           ,y_col=\"label\",subset=\"training\"\n",
    "                                            ,batch_size=64,seed=42,shuffle=True,validate_filenames=False\n",
    "                                            ,class_mode=\"categorical\"\n",
    "                                            ,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14400 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator=datagen.flow_from_dataframe(dataframe=df,directory=\"./rvl-cdip/data_final/\",x_col=\"path\"\n",
    "                                            ,y_col='label',subset=\"validation\"\n",
    "                                            ,batch_size=64,seed=42,shuffle=True\n",
    "                                            ,class_mode=\"categorical\"\n",
    "                                            ,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import random as rn\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(0)\n",
    "rn.seed(0)\n",
    "new_input = Input(shape=(256, 256,3))\n",
    "input_layer = Input(shape=(256,256,3),name = 'Input_Layer')\n",
    "\n",
    "model_vgg16 = VGG16(weights='imagenet', include_top=False,input_tensor=input_layer)\n",
    "for layer in model_vgg16.layers:\n",
    "\tlayer.trainable = False\n",
    "output_vgg16 = model_vgg16(input_layer)\n",
    "\n",
    "x= Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='x')(output_vgg16)\n",
    "Pool1 = MaxPool2D(pool_size=(2,2),strides=(2,2),padding='valid',data_format='channels_last',name='Pool1')(x)\n",
    "flatten = Flatten(data_format='channels_last',name='Flatten')(Pool1)\n",
    "\n",
    "FC1 = Dense(units=64,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),name='FC1')(flatten)\n",
    "FC2 = Dense(units=32,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=33),name='FC2')(FC1)\n",
    "Out = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(FC2)\n",
    "model=Model(inputs=input_layer,outputs=Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Layer (InputLayer)     [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "x (Conv2D)                   (None, 6, 6, 32)          147488    \n",
      "_________________________________________________________________\n",
      "Pool1 (MaxPooling2D)         (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 14,883,280\n",
      "Trainable params: 168,592\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "300/300 [==============================] - 6622s 22s/step - loss: 2.0765 - accuracy: 0.3236 - val_loss: 1.7455 - val_accuracy: 0.4395\n",
      "Epoch 2/3\n",
      "102/300 [=========>....................] - ETA: 53:59 - loss: 1.7217 - accuracy: 0.4436"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=300,validation_data=test_generator,validation_steps=225,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(0)\n",
    "rn.seed(0)\n",
    "input_layer = Input(shape=(224,224,3),name = 'Input_Layer')\n",
    "\n",
    "model_vgg16 = VGG16(weights='imagenet', include_top=False,input_tensor=input_layer)\n",
    "for layer in model_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "output_vgg16 = model_vgg16(input_layer)\n",
    "x=Conv2D(filters=4096,kernel_size=(7,7),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='x')(output_vgg16)\n",
    "y=Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='y')(x)\n",
    "Out = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(y)\n",
    "model=Model(inputs=input_layer,outputs=Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cd6338d898cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0moutput_vgg16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_vgg16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m x=Conv2D(filters=4096,kernel_size=(7,7),strides=(1,1),padding='valid',data_format='channels_last',\n\u001b[1;32m---> 16\u001b[1;33m               activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='x')(output_vgg16)\n\u001b[0m\u001b[0;32m     17\u001b[0m y=Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='valid',data_format='channels_last',\n\u001b[0;32m     18\u001b[0m               activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='y')(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Flatten, Dense,GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "input_layer = Input(shape=(224,224,3),name = 'Input_Layer')\n",
    "\n",
    "model_vgg16 = VGG16(weights='imagenet', include_top=False,input_tensor=input_layer)\n",
    "for layer in model_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model_vgg16.layers[-6:]:\n",
    "    layer.trainable = True\n",
    "output_vgg16 = model_vgg16(input_layer)\n",
    "x=Conv2D(filters=4096,kernel_size=(7,7),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='x')(output_vgg16)\n",
    "y=Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='y')(x)\n",
    "O=GlobalMaxPooling2D(data_format='channels_last')(y)\n",
    "Out = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(O)\n",
    "\n",
    "model=Model(inputs=input_layer,outputs=Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Layer (InputLayer)     [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "x (Conv2D)                   (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "y (Conv2D)                   (None, 1, 1, 16)          65552     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1, 1, 16)          272       \n",
      "=================================================================\n",
      "Total params: 117,545,056\n",
      "Trainable params: 102,830,368\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0445814e6d41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m225\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=300,validation_data=test_generator,validation_steps=225,epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
