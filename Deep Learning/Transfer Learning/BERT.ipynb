{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#192.168.43.256\n",
    "#all imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_tf_version():\n",
    "    assert((tf.__version__)>'2')\n",
    "    return True\n",
    "grader_tf_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read the dataset - Amazon fine food reviews\n",
    "review = pd.read_csv(r\"Reviews.csv\")\n",
    "#check the info of the dataset\n",
    "review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=pd.DataFrame()\n",
    "reviews[\"score\"]=review['Score']\n",
    "reviews[\"text\"]=review['Text']\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()\n",
    "#no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_score=[]\n",
    "for score in reviews[\"score\"]:\n",
    "    if score > 3:\n",
    "        new_score.append(1)\n",
    "    elif score <= 2:\n",
    "        new_score.append(0)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525814"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=reviews[reviews.score!=3]\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               text  Score\n",
       "0      5  I have bought several of the Vitality canned d...      1\n",
       "1      1  Product arrived labeled as Jumbo Salted Peanut...      0\n",
       "2      4  This is a confection that has been around a fe...      1\n",
       "3      2  If you are looking for the secret ingredient i...      0\n",
       "4      5  Great taffy at a great price.  There was a wid...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"Score\"]=new_score\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop('score', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_reviews():\n",
    "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
    "    assert(temp_shape == True)\n",
    "    return True\n",
    "grader_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordlen(x):\n",
    "    return len(x.split())\n",
    "reviews['len'] = reviews.text.apply(get_wordlen)\n",
    "reviews = reviews[reviews.len<50]\n",
    "reviews = reviews.sample(n=100000, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(clean, '', text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 100000/100000 [00:00<00:00, 155632.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "Text=[]\n",
    "for text in tqdm(reviews['text']):\n",
    "    Text.append(remove_html_tags(text))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def decontracted(phrase):\n",
    "    \"\"\"function for processing text data and removing unwanted characters\"\"\"\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"\\\\n\", \" \", phrase)\n",
    "    phrase = re.sub(r\"\\\\r\", \" \", phrase)\n",
    "    phrase = re.sub(r\"\\\\\", \" \", phrase)\n",
    "    phrase = re.sub('[^A-Z0-9a-z]+', \" \", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [6:10:46<00:00,  4.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Import stopwords with nltk.\n",
    "text=[]\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "for sentence in tqdm(Text):\n",
    "    sent = decontracted(sentence)\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words())\n",
    "    text.append(sent.lower().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop('Text', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"Text\"]=text\n",
    "y=reviews['Score'].values\n",
    "X=reviews.drop('Score', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=33,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the Pretrained Model from tensorflow HUB\n",
    "tf.keras.backend.clear_session()\n",
    "# maximum length of a seq in the data we have, for now i am making it as 75. You can change this\n",
    "max_seq_length = 55\n",
    "#BERT takes 3 inputs\n",
    "#this is input words. Sequence of words represented as integers\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "#mask vector if you are padding anything\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "\n",
    "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
    "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
    "#second seq segment vector are 1's\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "#bert layer \n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 55)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 55)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 55)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 109,482,241\n",
      "Trainable params: 0\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'keras_layer/Identity:0' shape=(None, 768) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Vocab file\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file,do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it has to give no error \n",
    "def grader_tokenize(tokenizer):\n",
    "    out = False\n",
    "    try:\n",
    "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
    "    except:\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text(sentence,max_seq,tokenizer):\n",
    "    max_seq-=2\n",
    "    all_tokens=[]\n",
    "    mask=[]\n",
    "    segment=[]\n",
    "    for i in range(sentence.shape[0]):\n",
    "        token=tokenizer.tokenize(sentence[i])\n",
    "        if len(token)> max_seq:\n",
    "            token=token[:max_seq]\n",
    "        tokens= ['[CLS]',*token,'[SEP]']  \n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+token +[\"[SEP]\"])+[0] * (max_seq - len(token))\n",
    "        mask_array=([1]*len(tokens)+ [0]*(max_seq +2 -len(tokens)))\n",
    "        seg_array=([0]*(max_seq+2))\n",
    "        all_tokens.append(one_token)\n",
    "        mask.append(mask_array)\n",
    "        segment.append(seg_array)\n",
    "    return np.array(all_tokens),np.array(mask),np.array(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=X_train['Text'].values\n",
    "test_text=X_test[\"Text\"].values\n",
    "\n",
    "X_train_tokens,X_train_mask,X_train_segment=convert_text(train_text,max_seq_length,tokenizer)\n",
    "X_test_tokens,X_test_mask,X_test_segment=convert_text(test_text,max_seq_length,tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_train():\n",
    "    out = False\n",
    "    \n",
    "    if type(X_train_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_train_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_train_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "\n",
    "grader_alltokens_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "##save all your results to disk so that, no need to run all again. \n",
    "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
    "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can load from disk\n",
    "X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
    "X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 55)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_test():\n",
    "    out = False\n",
    "    if type(X_test_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_test_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_test_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_alltokens_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_word_ids:0' shape=(None, 55) dtype=int32>,\n",
       " <tf.Tensor 'input_mask:0' shape=(None, 55) dtype=int32>,\n",
       " <tf.Tensor 'segment_ids:0' shape=(None, 55) dtype=int32>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'keras_layer/Identity:0' shape=(None, 768) dtype=float32>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have X_train_pooled_output, y_train\n",
    "#X_test_pooled_ouput, y_test\n",
    "\n",
    "#please use this grader to evaluate\n",
    "def greader_output():\n",
    "    assert(X_train_pooled_output.shape[1]==768)\n",
    "    assert(len(y_train)==len(X_train_pooled_output))\n",
    "    assert(X_test_pooled_output.shape[1]==768)\n",
    "    assert(len(y_test)==len(X_test_pooled_output))\n",
    "    assert(len(y_train.shape)==1)\n",
    "    assert(len(X_train_pooled_output.shape)==2)\n",
    "    assert(len(y_test.shape)==1)\n",
    "    assert(len(X_test_pooled_output.shape)==2)\n",
    "    return True\n",
    "greader_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rock",
   "language": "python",
   "name": "rock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
