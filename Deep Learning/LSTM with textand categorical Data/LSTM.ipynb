{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data (109248, 17)\n",
      "--------------------------------------------------\n",
      "The attributes of data : ['Unnamed: 0' 'id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved']\n"
     ]
    }
   ],
   "source": [
    "project_data = pd.read_csv('train_data.csv')\n",
    "resource_data = pd.read_csv('resources.csv')\n",
    "print(\"Number of data points in train data\", project_data.shape)\n",
    "print('-'*50)\n",
    "print(\"The attributes of data :\", project_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data (1541272, 4)\n",
      "['id' 'description' 'quantity' 'price']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of data points in train data\", resource_data.shape)\n",
    "print(resource_data.columns.values)\n",
    "resource_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                           0\n",
      "id                                                   0\n",
      "teacher_id                                           0\n",
      "teacher_prefix                                       3\n",
      "school_state                                         0\n",
      "project_submitted_datetime                           0\n",
      "project_grade_category                               0\n",
      "project_subject_categories                           0\n",
      "project_subject_subcategories                        0\n",
      "project_title                                        0\n",
      "project_essay_1                                      0\n",
      "project_essay_2                                      0\n",
      "project_essay_3                                 105490\n",
      "project_essay_4                                 105490\n",
      "project_resource_summary                             0\n",
      "teacher_number_of_previously_posted_projects         0\n",
      "project_is_approved                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in python : https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b\n",
    "\n",
    "print (project_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna column pandas :https://stackoverflow.com/a/23235618/8363466\n",
    "project_data = project_data[pd.notnull(project_data['teacher_prefix'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogories = list(project_data['project_subject_categories'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "cat_list = []\n",
    "for i in catogories:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp+=j.strip()+\" \" #\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_') # we are replacing the & value into \n",
    "    cat_list.append(temp.strip())\n",
    "    \n",
    "project_data['clean_categories'] = cat_list\n",
    "project_data.drop(['project_subject_categories'], axis=1, inplace=True)\n",
    "\n",
    "my_counter = Counter()\n",
    "for word in project_data['clean_categories'].values:\n",
    "    my_counter.update(word.split())\n",
    "\n",
    "cat_dict = dict(my_counter)\n",
    "sorted_cat_dict = dict(sorted(cat_dict.items(), key=lambda kv: kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_catogories = list(project_data['project_subject_subcategories'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "\n",
    "sub_cat_list = []\n",
    "for i in sub_catogories:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_')\n",
    "    sub_cat_list.append(temp.strip())\n",
    "\n",
    "project_data['clean_subcategories'] = sub_cat_list\n",
    "project_data.drop(['project_subject_subcategories'], axis=1, inplace=True)\n",
    "\n",
    "# count of all the words in corpus python: https://stackoverflow.com/a/22898595/4084039\n",
    "my_counter = Counter()\n",
    "for word in project_data['clean_subcategories'].values:\n",
    "    my_counter.update(word.split())\n",
    "    \n",
    "sub_cat_dict = dict(my_counter)\n",
    "sorted_sub_cat_dict = dict(sorted(sub_cat_dict.items(), key=lambda kv: kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging all essays\n",
    "project_data[\"essay\"] = project_data[\"project_essay_1\"].map(str) +\\\n",
    "                        project_data[\"project_essay_2\"].map(str) + \\\n",
    "                        project_data[\"project_essay_3\"].map(str) + \\\n",
    "                        project_data[\"project_essay_4\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopword= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    \"\"\"function for processing text data and removing unwanted characters\"\"\"\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"\\\\n\", \" \", phrase)\n",
    "    phrase = re.sub(r\"\\\\r\", \" \", phrase)\n",
    "    phrase = re.sub(r\"\\\\\", \" \", phrase)\n",
    "    phrase = re.sub('[^A-Z0-9a-z]+', \" \", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grades_PreK_2    44225\n",
       "Grades_3_5       37135\n",
       "Grades_6_8       16923\n",
       "Grades_9_12      10962\n",
       "Name: project_grade_category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['project_grade_category'] =  project_data['project_grade_category'].str.replace(\" \", \"_\")\n",
    "project_data['project_grade_category'] =  project_data['project_grade_category'].str.replace(\"-\", \"_\")\n",
    "project_data['project_grade_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data.columns\n",
    "project_data.drop(['Unnamed: 0'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "digit_in_summary=[]\n",
    "summary_array=project_data[\"project_resource_summary\"].values\n",
    "for i in summary_array:\n",
    "    digit=re.search(r'\\d', i)\n",
    "    if (bool(digit)==False):\n",
    "        digit_in_summary.append(0)\n",
    "    else:\n",
    "        digit_in_summary.append(1)\n",
    "project_data[\"digit\"]=digit_in_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mrs.       57269\n",
       "Ms.        38955\n",
       "Mr.        10648\n",
       "Teacher     2360\n",
       "Dr.           13\n",
       "Name: teacher_prefix, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['teacher_prefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>459.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>515.89</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   price  quantity\n",
       "0  p000001  459.56         7\n",
       "1  p000002  515.89        21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "price_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = pd.merge(project_data, price_data, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>digit</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88012</th>\n",
       "      <td>p043212</td>\n",
       "      <td>fa2f220b537e8653fb48878ebb38044d</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>PA</td>\n",
       "      <td>2017-04-27 21:30:17</td>\n",
       "      <td>Grades_PreK_2</td>\n",
       "      <td>Food to Bring Home!</td>\n",
       "      <td>I currently have 25 six- and seven-year-old st...</td>\n",
       "      <td>I would love if my students could bring home f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need Life Essential Healthy foods ...</td>\n",
       "      <td>451</td>\n",
       "      <td>1</td>\n",
       "      <td>Warmth Care_Hunger</td>\n",
       "      <td>Warmth Care_Hunger</td>\n",
       "      <td>I currently have 25 six- and seven-year-old st...</td>\n",
       "      <td>0</td>\n",
       "      <td>123.71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                        teacher_id teacher_prefix school_state  \\\n",
       "88012  p043212  fa2f220b537e8653fb48878ebb38044d           Mrs.           PA   \n",
       "\n",
       "      project_submitted_datetime project_grade_category        project_title  \\\n",
       "88012        2017-04-27 21:30:17          Grades_PreK_2  Food to Bring Home!   \n",
       "\n",
       "                                         project_essay_1  \\\n",
       "88012  I currently have 25 six- and seven-year-old st...   \n",
       "\n",
       "                                         project_essay_2 project_essay_3  \\\n",
       "88012  I would love if my students could bring home f...             NaN   \n",
       "\n",
       "      project_essay_4                           project_resource_summary  \\\n",
       "88012             NaN  My students need Life Essential Healthy foods ...   \n",
       "\n",
       "       teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "88012                                           451                    1   \n",
       "\n",
       "         clean_categories clean_subcategories  \\\n",
       "88012  Warmth Care_Hunger  Warmth Care_Hunger   \n",
       "\n",
       "                                                   essay  digit   price  \\\n",
       "88012  I currently have 25 six- and seven-year-old st...      0  123.71   \n",
       "\n",
       "       quantity  \n",
       "88012         8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data[project_data['teacher_number_of_previously_posted_projects']==project_data['teacher_number_of_previously_posted_projects'].max()]\n",
    "# row of max value of teacher_number_of_previously_posted_projects row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My students are English learners that are working on English as their second or third languages. We are a melting pot of refugees, immigrants, and native-born Americans bringing the gift of language to our school. \\\\r\\\\n\\\\r\\\\n We have over 24 languages represented in our English Learner program with students at every level of mastery.  We also have over 40 countries represented with the families within our school.  Each student brings a wealth of knowledge and experiences to us that open our eyes to new cultures, beliefs, and respect.\\\\\"The limits of your language are the limits of your world.\\\\\"-Ludwig Wittgenstein  Our English learner\\'s have a strong support system at home that begs for more resources.  Many times our parents are learning to read and speak English along side of their children.  Sometimes this creates barriers for parents to be able to help their child learn phonetics, letter recognition, and other reading skills.\\\\r\\\\n\\\\r\\\\nBy providing these dvd\\'s and players, students are able to continue their mastery of the English language even if no one at home is able to assist.  All families with students within the Level 1 proficiency status, will be a offered to be a part of this program.  These educational videos will be specially chosen by the English Learner Teacher and will be sent home regularly to watch.  The videos are to help the child develop early reading skills.\\\\r\\\\n\\\\r\\\\nParents that do not have access to a dvd player will have the opportunity to check out a dvd player to use for the year.  The plan is to use these videos and educational dvd\\'s for the years to come for other EL students.\\\\r\\\\nnannan'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TAKING FIRST ESSAY\n",
    "project_row_0=project_data[\"essay\"].values[0]\n",
    "project_row_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My students are English learners that are working on English as their second or third languages We are a melting pot of refugees immigrants and native born Americans bringing the gift of language to our school We have over 24 languages represented in our English Learner program with students at every level of mastery We also have over 40 countries represented with the families within our school Each student brings a wealth of knowledge and experiences to us that open our eyes to new cultures beliefs and respect The limits of your language are the limits of your world Ludwig Wittgenstein Our English learner s have a strong support system at home that begs for more resources Many times our parents are learning to read and speak English along side of their children Sometimes this creates barriers for parents to be able to help their child learn phonetics letter recognition and other reading skills By providing these dvd s and players students are able to continue their mastery of the English language even if no one at home is able to assist All families with students within the Level 1 proficiency status will be a offered to be a part of this program These educational videos will be specially chosen by the English Learner Teacher and will be sent home regularly to watch The videos are to help the child develop early reading skills Parents that do not have access to a dvd player will have the opportunity to check out a dvd player to use for the year The plan is to use these videos and educational dvd s for the years to come for other EL students nannan'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "processed_phrase=decontracted(project_row_0)\n",
    "processed_phrase#preprossed project_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 109245/109245 [00:04<00:00, 24242.74it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#preprocess title \n",
    "#delete  \"project_title\" column and add preprocessed_titles\n",
    "from tqdm import tqdm\n",
    "preprocessed_titles=[]\n",
    "for sentence in tqdm(project_data['project_title'].values):\n",
    "    sent = decontracted(sentence)\n",
    "    sent = ' '.join(e for e in sent.split() if e.lower() not in stopword)\n",
    "    preprocessed_titles.append(sent.lower().strip())\n",
    "project_data['preprocessed_title']=preprocessed_titles\n",
    "project_data.drop('project_title', axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          educational support english learners home\n",
       "1                   wanted projector hungry learners\n",
       "2    soccer equipment awesome middle school students\n",
       "3                             techie kindergarteners\n",
       "4                             interactive math tools\n",
       "Name: preprocessed_title, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['preprocessed_title'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 109245/109245 [01:28<00:00, 1231.14it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_essays=[]#preprocess essay column  and append to project_data\n",
    "for sentence in tqdm(project_data['essay'].values):\n",
    "    sent = decontracted(sentence)\n",
    "    sent = ' '.join(e for e in sent.split() if e.lower() not in stopword)\n",
    "    preprocessed_essays.append(sent.lower().strip())\n",
    "project_data['preprocessed_essays']=preprocessed_essays\n",
    "project_data.drop('essay', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_essay_1', 'project_essay_2', 'project_essay_3',\n",
       "       'project_essay_4', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'clean_categories', 'clean_subcategories', 'digit', 'price', 'quantity',\n",
       "       'preprocessed_title', 'preprocessed_essays'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca    15387\n",
       "tx     7396\n",
       "ny     7318\n",
       "fl     6185\n",
       "nc     5091\n",
       "il     4350\n",
       "ga     3963\n",
       "sc     3935\n",
       "mi     3161\n",
       "pa     3108\n",
       "in     2620\n",
       "mo     2576\n",
       "oh     2467\n",
       "la     2394\n",
       "ma     2389\n",
       "wa     2334\n",
       "ok     2276\n",
       "nj     2237\n",
       "az     2147\n",
       "va     2045\n",
       "wi     1827\n",
       "al     1762\n",
       "ut     1731\n",
       "tn     1688\n",
       "ct     1663\n",
       "md     1514\n",
       "nv     1367\n",
       "ms     1323\n",
       "ky     1304\n",
       "or     1242\n",
       "mn     1208\n",
       "co     1111\n",
       "ar     1049\n",
       "id      693\n",
       "ia      666\n",
       "ks      634\n",
       "nm      557\n",
       "dc      516\n",
       "hi      507\n",
       "me      505\n",
       "wv      503\n",
       "nh      348\n",
       "ak      345\n",
       "de      343\n",
       "ne      309\n",
       "sd      300\n",
       "ri      285\n",
       "mt      245\n",
       "nd      143\n",
       "wy       98\n",
       "vt       80\n",
       "Name: school_state, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing school state converting to lowercase\n",
    "project_data['school_state'] = project_data['school_state'].str.lower()\n",
    "project_data['school_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data.columns\n",
    "project_data['teacher_prefix'] = project_data['teacher_prefix'].str.replace('.','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_col=['id','project_submitted_datetime','project_essay_1','project_essay_2','project_essay_3','project_essay_4',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_grade_category', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'clean_categories', 'clean_subcategories', 'digit', 'price', 'quantity',\n",
       "       'preprocessed_title', 'preprocessed_essays'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in remove_col:\n",
    "    project_data.drop(col,axis=1,inplace=True)\n",
    "\n",
    "project_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 109245/109245 [00:09<00:00, 11172.05it/s]\n"
     ]
    }
   ],
   "source": [
    "resource_summary=[]#preprocess project_resource_summary column  and append to project_data\n",
    "for sentence in tqdm(project_data[\"project_resource_summary\"].values):\n",
    "    sent = decontracted(sentence)\n",
    "    sent = ' '.join(e for e in sent.split() if e.lower() not in stopword)\n",
    "    resource_summary.append(sent.lower().strip())\n",
    "project_data['resource_summary']=resource_summary\n",
    "project_data.drop('project_resource_summary', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['resource_summary'].head(10)\n",
    "project_data.drop('teacher_id',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "number of nan values 0\n"
     ]
    }
   ],
   "source": [
    "# check if we have any nan values are there\n",
    "print(project_data['teacher_prefix'].isnull().values.any())\n",
    "print(\"number of nan values\",project_data['teacher_prefix'].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data[\"sum_integers\"]=project_data['teacher_number_of_previously_posted_projects']  +\\\n",
    "                                    project_data['digit']  + \\\n",
    "                                    project_data['price'] + project_data['quantity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>digit</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>preprocessed_title</th>\n",
       "      <th>preprocessed_essays</th>\n",
       "      <th>resource_summary</th>\n",
       "      <th>sum_integers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrs</td>\n",
       "      <td>in</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>esl literacy</td>\n",
       "      <td>0</td>\n",
       "      <td>154.60</td>\n",
       "      <td>23</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "      <td>students need opportunities practice beginning...</td>\n",
       "      <td>177.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr</td>\n",
       "      <td>fl</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>history_civics health_sports</td>\n",
       "      <td>civics_government teamsports</td>\n",
       "      <td>0</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "      <td>students need projector help viewing education...</td>\n",
       "      <td>307.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ms</td>\n",
       "      <td>az</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>health_sports</td>\n",
       "      <td>health_wellness teamsports</td>\n",
       "      <td>0</td>\n",
       "      <td>516.85</td>\n",
       "      <td>22</td>\n",
       "      <td>soccer equipment awesome middle school students</td>\n",
       "      <td>true champions always ones win guts mia hamm q...</td>\n",
       "      <td>students need shine guards athletic socks socc...</td>\n",
       "      <td>539.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  teacher_prefix school_state project_grade_category  \\\n",
       "0            mrs           in          grades_prek_2   \n",
       "1             mr           fl             grades_6_8   \n",
       "2             ms           az             grades_6_8   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                             0                    0   \n",
       "1                                             7                    1   \n",
       "2                                             1                    0   \n",
       "\n",
       "               clean_categories           clean_subcategories  digit   price  \\\n",
       "0             literacy_language                  esl literacy      0  154.60   \n",
       "1  history_civics health_sports  civics_government teamsports      0  299.00   \n",
       "2                 health_sports    health_wellness teamsports      0  516.85   \n",
       "\n",
       "   quantity                               preprocessed_title  \\\n",
       "0        23        educational support english learners home   \n",
       "1         1                 wanted projector hungry learners   \n",
       "2        22  soccer equipment awesome middle school students   \n",
       "\n",
       "                                 preprocessed_essays  \\\n",
       "0  students english learners working english seco...   \n",
       "1  students arrive school eager learn polite gene...   \n",
       "2  true champions always ones win guts mia hamm q...   \n",
       "\n",
       "                                    resource_summary  sum_integers  \n",
       "0  students need opportunities practice beginning...        177.60  \n",
       "1  students need projector help viewing education...        307.00  \n",
       "2  students need shine guards athletic socks socc...        539.85  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert all columns to lowercase \n",
    "project_data['project_grade_category'] = project_data['project_grade_category'].str.lower()\n",
    "project_data['teacher_prefix'] = project_data['teacher_prefix'].str.lower()\n",
    "project_data['clean_subcategories'] = project_data['clean_subcategories'].str.lower()\n",
    "project_data['clean_categories'] = project_data['clean_categories'].str.lower()\n",
    "\n",
    "project_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add total text to project_data\n",
    "project_data['input_text'] = project_data['preprocessed_title'] + ' ' + project_data['preprocessed_essays'] + ' ' + project_data['resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = project_data['project_is_approved'].values\n",
    "project_data.drop(['project_is_approved'], axis=1, inplace=True)\n",
    "X = project_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>sum_integers</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrs</td>\n",
       "      <td>in</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>esl literacy</td>\n",
       "      <td>177.60</td>\n",
       "      <td>educational support english learners home stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr</td>\n",
       "      <td>fl</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>history_civics health_sports</td>\n",
       "      <td>civics_government teamsports</td>\n",
       "      <td>307.00</td>\n",
       "      <td>wanted projector hungry learners students arri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ms</td>\n",
       "      <td>az</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>health_sports</td>\n",
       "      <td>health_wellness teamsports</td>\n",
       "      <td>539.85</td>\n",
       "      <td>soccer equipment awesome middle school student...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrs</td>\n",
       "      <td>ky</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>literacy_language math_science</td>\n",
       "      <td>literacy mathematics</td>\n",
       "      <td>240.90</td>\n",
       "      <td>techie kindergarteners work unique school fill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrs</td>\n",
       "      <td>tx</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>math_science</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>72.98</td>\n",
       "      <td>interactive math tools second grade classroom ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  teacher_prefix school_state project_grade_category  \\\n",
       "0            mrs           in          grades_prek_2   \n",
       "1             mr           fl             grades_6_8   \n",
       "2             ms           az             grades_6_8   \n",
       "3            mrs           ky          grades_prek_2   \n",
       "4            mrs           tx          grades_prek_2   \n",
       "\n",
       "                 clean_categories           clean_subcategories  sum_integers  \\\n",
       "0               literacy_language                  esl literacy        177.60   \n",
       "1    history_civics health_sports  civics_government teamsports        307.00   \n",
       "2                   health_sports    health_wellness teamsports        539.85   \n",
       "3  literacy_language math_science          literacy mathematics        240.90   \n",
       "4                    math_science                   mathematics         72.98   \n",
       "\n",
       "                                          input_text  \n",
       "0  educational support english learners home stud...  \n",
       "1  wanted projector hungry learners students arri...  \n",
       "2  soccer equipment awesome middle school student...  \n",
       "3  techie kindergarteners work unique school fill...  \n",
       "4  interactive math tools second grade classroom ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove not useful columns\n",
    "\n",
    "col=['digit','price','quantity','teacher_number_of_previously_posted_projects','preprocessed_essays','preprocessed_title','resource_summary']\n",
    "for column in col:\n",
    "    project_data.drop(column, axis=1, inplace=True)\n",
    "project_data.head(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_train(data):\n",
    "    c=CountVectorizer(lowercase=False)\n",
    "    v=c.fit_transform(data)\n",
    "    \n",
    "    frequency=v.sum(axis=0).A1\n",
    "    index=frequency.argsort()\n",
    "\n",
    "    features=c.get_feature_names()\n",
    "    rank_d={}\n",
    "    count=1\n",
    "    for item in index[::-1]:\n",
    "        feature=features[item]\n",
    "        rank_d[feature]=count\n",
    "        count+=1\n",
    "    return features,rank_d\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_rest(data,d):\n",
    "    #convert into tokens\n",
    "    token_list=[]\n",
    "    for sent in data:\n",
    "        words = sent.split()\n",
    "        token_sub = []\n",
    "        for item in words:\n",
    "            if(item in d):\n",
    "                token_sub.append(d[item])\n",
    "\n",
    "        token_list.append(token_sub)\n",
    "    return token_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc', 'de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in', 'ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn', 'mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj', 'nm', 'nv', 'ny', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx', 'ut', 'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
      "**************************************************\n",
      "{'ca': 1, 'tx': 2, 'ny': 3, 'fl': 4, 'nc': 5, 'il': 6, 'ga': 7, 'sc': 8, 'mi': 9, 'pa': 10, 'in': 11, 'mo': 12, 'oh': 13, 'la': 14, 'ma': 15, 'wa': 16, 'ok': 17, 'nj': 18, 'az': 19, 'va': 20, 'wi': 21, 'al': 22, 'ut': 23, 'tn': 24, 'ct': 25, 'md': 26, 'nv': 27, 'ms': 28, 'ky': 29, 'or': 30, 'mn': 31, 'co': 32, 'ar': 33, 'id': 34, 'ia': 35, 'ks': 36, 'nm': 37, 'dc': 38, 'hi': 39, 'me': 40, 'wv': 41, 'nh': 42, 'ak': 43, 'de': 44, 'ne': 45, 'sd': 46, 'ri': 47, 'mt': 48, 'nd': 49, 'wy': 50, 'vt': 51}\n",
      "**************************************************\n",
      "state name: in\n",
      "**************************************************\n",
      "token value [11]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "features, dictio = for_train(project_data['school_state'])\n",
    "print(features)\n",
    "print(50 *\"*\")\n",
    "print(dictio)\n",
    "print(50 *\"*\")\n",
    "\n",
    "tokenize_data = for_rest(project_data['school_state'], dictio)\n",
    "print(\"state name:\", project_data['school_state'][0])\n",
    "print(50 *\"*\")\n",
    "\n",
    "print(\"token value\",tokenize_data[0])\n",
    "print(50 *\"*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Set (61176, 7) (61176,)\n",
      "Cross Validate Data Set (15295, 7) (15295,)\n",
      "Test Data Set (32774, 7) (32774,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "print('Train Data Set', X_train.shape, y_train.shape)\n",
    "print('Cross Validate Data Set', X_cv.shape, y_cv.shape)\n",
    "print('Test Data Set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61176 (61176,)\n",
      "15295 (15295,)\n",
      "32774 (32774,)\n",
      "['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc', 'de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in', 'ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn', 'mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj', 'nm', 'nv', 'ny', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx', 'ut', 'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# - school_state : categorical data\n",
    "(state_features, dictio) =for_train(X_train['school_state'].values)\n",
    "\n",
    "X_train_state = for_rest(X_train['school_state'].values, dictio)\n",
    "X_cv_state = for_rest(X_cv['school_state'].values, dictio)\n",
    "X_test_state = for_rest(X_test['school_state'].values, dictio)\n",
    "\n",
    "print(len(X_train_state), y_train.shape)\n",
    "print(len(X_cv_state), y_cv.shape)\n",
    "print(len(X_test_state), y_test.shape)\n",
    "print(state_features)\n",
    "print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61176 (61176,)\n",
      "15295 (15295,)\n",
      "32774 (32774,)\n",
      "['dr', 'mr', 'mrs', 'ms', 'teacher']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "(teacher_features, dictio) =  for_train(X_train['teacher_prefix'].values)# Fit has to happen only on train data\n",
    "\n",
    "X_train_teacher = for_rest(X_train['teacher_prefix'].values, dictio)\n",
    "X_cv_teacher = for_rest(X_cv['teacher_prefix'].values, dictio)\n",
    "X_test_teacher = for_rest(X_test['teacher_prefix'].values, dictio)\n",
    "\n",
    "print(len(X_train_teacher), y_train.shape)\n",
    "print(len(X_cv_teacher), y_cv.shape)\n",
    "print(len(X_test_teacher), y_test.shape)\n",
    "print(teacher_features)\n",
    "\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61176 (61176,)\n",
      "15295 (15295,)\n",
      "32774 (32774,)\n",
      "['appliedlearning', 'care_hunger', 'health_sports', 'history_civics', 'literacy_language', 'math_science', 'music_arts', 'specialneeds', 'warmth']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# clean_categories : categorical data\n",
    "(categories_features,dictio) =  for_train(X_train['clean_categories'].values)\n",
    "\n",
    "X_train_categories = for_rest(X_train['clean_categories'].values,dictio)\n",
    "X_cv_categories = for_rest(X_cv['clean_categories'].values, dictio)\n",
    "X_test_categories = for_rest(X_test['clean_categories'].values, dictio)\n",
    "\n",
    "print(len(X_train_categories), y_train.shape)\n",
    "print(len(X_cv_categories), y_cv.shape)\n",
    "print(len(X_test_categories), y_test.shape)\n",
    "print(categories_features)\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61176 (61176,)\n",
      "15295 (15295,)\n",
      "32774 (32774,)\n",
      "['appliedsciences', 'care_hunger', 'charactereducation', 'civics_government', 'college_careerprep', 'communityservice', 'earlydevelopment', 'economics', 'environmentalscience', 'esl', 'extracurricular', 'financialliteracy', 'foreignlanguages', 'gym_fitness', 'health_lifescience', 'health_wellness', 'history_geography', 'literacy', 'literature_writing', 'mathematics', 'music', 'nutritioneducation', 'other', 'parentinvolvement', 'performingarts', 'socialsciences', 'specialneeds', 'teamsports', 'visualarts', 'warmth']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# clean_subcategories : categorical data\n",
    "(subcategories_features,dictio) =  for_train(X_train['clean_subcategories'].values)\n",
    "\n",
    "X_train_subcategories = for_rest(X_train['clean_subcategories'].values,dictio)\n",
    "X_cv_subcategories = for_rest(X_cv['clean_subcategories'].values, dictio)\n",
    "X_test_subcategories = for_rest(X_test['clean_subcategories'].values, dictio)\n",
    "\n",
    "print(len(X_train_subcategories), y_train.shape)\n",
    "print(len(X_cv_subcategories), y_cv.shape)\n",
    "print(len(X_test_subcategories), y_test.shape)\n",
    "print(subcategories_features)\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61176 (61176,)\n",
      "15295 (15295,)\n",
      "32774 (32774,)\n",
      "['grades_3_5', 'grades_6_8', 'grades_9_12', 'grades_prek_2']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# for project grade category\n",
    "(grade_category_features, dictio) =  for_train(X_train['project_grade_category'].values)# Fit has to happen only on train data\n",
    "\n",
    "X_train_grade = for_rest(X_train['project_grade_category'].values, dictio)\n",
    "X_cv_grade = for_rest(X_cv['project_grade_category'].values, dictio)\n",
    "X_test_grade = for_rest(X_test['project_grade_category'].values,dictio)\n",
    "\n",
    "print(len(X_train_grade), y_train.shape)\n",
    "print(len(X_cv_grade), y_cv.shape)\n",
    "print(len(X_test_grade), y_test.shape)\n",
    "print(grade_category_features)\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find length of maximum essay length\n",
    "maxlen=0\n",
    "for i in X_train['input_text'].values:\n",
    "    words=i.split()\n",
    "    if len(words)> maxlen:\n",
    "        maxlen=len(words)\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61176, 300)\n",
      "(15295, 300)\n",
      "(32774, 300)\n"
     ]
    }
   ],
   "source": [
    "max_len=300\n",
    "def padding(data,max_length):\n",
    "    padded=pad_sequences(data,maxlen=max_length,padding='post')\n",
    "    return padded\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts(X_train['input_text'])\n",
    "vocab_size=len(token.word_index)\n",
    "seq1=token.texts_to_sequences(X_train[\"input_text\"])\n",
    "X_train_text=padding(seq1,max_len)\n",
    "print(X_train_text.shape)\n",
    "\n",
    "data2 = token.texts_to_sequences(X_cv['input_text'])\n",
    "X_cv_text = padding(data2,max_len)\n",
    "print(X_cv_text.shape)\n",
    "data3= token.texts_to_sequences(X_test['input_text'])\n",
    "X_test_text = padding(data3,max_len)\n",
    "print(X_test_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding other columns\n",
    "X_train_state=padding(X_train_state,1)\n",
    "X_test_state=padding(X_test_state,1)\n",
    "X_cv_state=padding(X_cv_state,1)\n",
    "\n",
    "\n",
    "X_train_grade=padding(X_train_grade,1)\n",
    "X_test_grade=padding(X_test_grade,1)\n",
    "X_cv_grade=padding(X_cv_grade,1)\n",
    "\n",
    "X_train_cat=padding(X_train_categories,1)\n",
    "X_test_cat=padding(X_test_categories,1)\n",
    "X_cv_cat=padding(X_cv_categories,1)\n",
    "\n",
    "X_train_sub=padding(X_train_subcategories,1)\n",
    "X_test_sub=padding(X_test_subcategories,1)\n",
    "X_cv_sub=padding(X_cv_subcategories,1)\n",
    "\n",
    "X_train_teacher=padding(X_train_teacher,1)\n",
    "X_test_teacher=padding(X_test_teacher,1)\n",
    "X_cv_teacher=padding(X_cv_teacher,1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25094     7    12   112   176     2   327     1    20    86   134   108\n",
      "   202    48   783  1046    84   427  1507    61     5    20     2   132\n",
      "     7    98     7   427    61    30   104  1046    80  1528   808    97\n",
      "   116    97   140   156     4   146    14     8   427    14   515    69\n",
      "    58    30    26     4    64  1067     3   675   138  1688    92   194\n",
      "   427    61  2561    64  2238   347    62    22   297   426     7   320\n",
      "    51   175    34  2148    77   463    38    17    22   250    22   426\n",
      "   427   138     6     1  1554   427    61   451  1067    64    48    30\n",
      "    30    20     2   208   651  1072     4   253    61   700    30    64\n",
      "     2     4   368   159    11     1     3    69   138    64   451    58\n",
      "    23     6   194    29    21    46   185     3   675   416  1688   194\n",
      "   427    61  2561     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_text[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7773   941  1159   294     2  1264   725     2   102   239 13623     1\n",
      "   530   323  1147    32   113     2   239  4806     1  2801    62   159\n",
      "  2696   986    41  1636    84    48   251    30   479   664     4     1\n",
      "   482   692   116     7   854  2508   203   445   218     5    75   131\n",
      "   160    39    19    92   636    24   100     7     1  4732   778   548\n",
      "     4   941  1159   170   250   941  1159   590   186     2    69   941\n",
      "  1159  1978   290    39   191  1331    39  1863   132  1897   219  3871\n",
      "  1712  1004   198  2554  2253   228  2727   883  1126   980   680     1\n",
      "     7   636   122    69    48   892  1149  3941  2950   917   941  1159\n",
      "   524    50   199    49    39    11     1     3  9280  4783   714   423\n",
      "  5287    69  1664    24     3   941  1159  3417  1832    43   392   282\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding_matrix_shape : (48399, 300)\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt.txt',encoding='utf8')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "embedding_matrix = np.zeros((vocab_size+1, 300))\n",
    "for word, i in token.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "print(\"Embedding_matrix_shape :\",embedding_matrix.shape )\n",
    "essay_matrix=embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_cv = to_categorical(y_cv)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(y_true, y_pred):\n",
    "    return tf.compat.v1.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 300, 300)     14519700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 300, 128)     219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         104         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         10          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         100         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        19250       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         30          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 38400)        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 50)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 5)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           32          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38477)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          4925184     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128)          512         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           2064        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 19,686,668\n",
      "Trainable params: 5,166,712\n",
      "Non-trainable params: 14,519,956\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#input 1\n",
    "#from keras.callbacks import Tensorboard\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from time import time\n",
    "from tensorflow.python import keras\n",
    "from keras.initializers import he_normal,glorot_normal\n",
    "from keras.regularizers import l1,l2\n",
    "from keras import regularizers\n",
    "from keras import Model,Input\n",
    "from keras.layers import SpatialDropout1D, LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "input1=Input(shape=(300,))\n",
    "y1=Embedding(vocab_size+1,output_dim=300,weights=[essay_matrix],trainable=False)(input1)\n",
    "y1=LSTM(128,recurrent_dropout=0.5,kernel_regularizer=regularizers.l2(0.001),return_sequences=True)(y1)\n",
    "y1=Flatten()(y1)\n",
    "\n",
    "input2 = Input(shape=(1,))\n",
    "y2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "y2 = Flatten()(y2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "y3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "y3 = Flatten()(y3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "y4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "y4 = Flatten()(y4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "y5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "y5 = Flatten()(y5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "y6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "y6 = Flatten()(y6)\n",
    "\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "y7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#concat all inputs \n",
    "concatenate= concatenate([y1,y2,y3,y4,y5,y6,y7])\n",
    "\n",
    "x = Dense(128,kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concatenate)\n",
    "x=Dropout(0.6)(x)\n",
    "x=BatchNormalization()(x)\n",
    "x = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.6)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0003,decay = 1e-3),metrics=['accuracy',auc_roc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=ModelCheckpoint('model_1.h5',monitor='val_accuracy',save_best_only=True,mode='max')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "callbacks=[checkpoint,earlystop,tensorboard]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 90/478 [====>.........................] - ETA: 25:22 - loss: 1.0363 - accuracy: 0.6806 - auc_roc: 0.5273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-bbfefa6272fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit([X_train_text,X_train_state,X_train_grade,X_train_cat,X_train_sub,\n\u001b[1;32m----> 2\u001b[1;33m                X_train_teacher,X_train['sum_integers']], y_train, epochs=20,verbose=1,batch_size=128,validation_data=([X_cv_text,X_cv_state,X_cv_grade,X_cv_cat,X_cv_sub,X_cv_teacher,X_cv['sum_integers']]  , y_cv),callbacks =callbacks )\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([X_train_text,X_train_state,X_train_grade,X_train_cat,X_train_sub,\n",
    "               X_train_teacher,X_train['sum_integers']], y_train, epochs=20,verbose=1,batch_size=128,validation_data=([X_cv_text,X_cv_state,X_cv_grade,X_cv_cat,X_cv_sub,X_cv_teacher,X_cv['sum_integers']]  , y_cv),callbacks =callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'IDF score')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MODEL-2\n",
    "#tf-idf processed_essay\n",
    "import matplotlib.pyplot as plt\n",
    "tf_idf = TfidfVectorizer()\n",
    "text = tf_idf.fit_transform(X_train[\"input_text\"].values)\n",
    "plt.boxplot(tf_idf.idf_)\n",
    "plt.ylabel(\"IDF score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 15 percentile of idf score is : [8.21486409]\n",
      "The 80 percentile of idf score is : [11.3283794]\n"
     ]
    }
   ],
   "source": [
    "#selecting values between 15th and 85th percentile idf score\n",
    "print(\"The 15 percentile of idf score is :\", np.percentile(tf_idf.idf_,[15]))\n",
    "print(\"The 80 percentile of idf score is :\",np.percentile(tf_idf.idf_,[80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.percentile(tf_idf.idf_,[15])\n",
    "b=np.percentile(tf_idf.idf_,[80])\n",
    "feature_select=zip(tf_idf.get_feature_names(),tf_idf.idf_)\n",
    "name=[]\n",
    "for x,y in feature_select:\n",
    "    if y>=a and y<=b:\n",
    "        name.append(x)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000s', '001', '002', '003', '005nannan', '00am', '00p', '00pm', '01', '010', '0125', '01ip', '02', '024', '025', '03', '030', '03074', '0315', '04', '04112016', '047', '05', '050', '05a', '05pm', '06', '060', '06ip', '07', '08', '084', '09', '0f', '0n', '0s', '0ver', '1000blackgirlbooks', '1001', '1009', '100ft', '100m', '100s', '100th', '1017', '102', '1020', '1022', '103', '1032', '1033', '104', '105', '1057', '106', '1065', '107', '1070', '108', '1080p', '1082', '1084', '109', '10k', '10lb', '10pk', '10pm', '10s', '10the', '10u', '10w', '10x', '10x10', '10yrs', '1100', '11000', '1104', '111', '111s', '112', '1120', '11242', '112th', '113', '113th', '114', '115', '116', '117', '118', '11e', '11pm', '11x14', '11x17', '11x25', '1200', '12000', '1201be', '1202', '1204', '120th', '121', '1212', '122', '122514', '123', '1233', '123s', '124', '1250', '126', '127', '1279', '128', '1285', '128gb', '129', '12bt', '12ft', '12inch', '12lb', '12pm', '12u', '12x', '12x16', '1300', '1307', '130ish', '130lb', '131', '1311', '131210', '1318110', '132', '133', '134', '1340', '134th', '135', '1350', '1354', '1358', '136', '137', '138', '139', '13th', '140', '1400', '141', '142', '1433', '144', '1440', '145', '1450', '146', '1469021285', '147', '1475', '148', '149', '1491', '14th', '1500', '1505', '150th', '150tmplus', '151', '152', '153', '1530', '153rd', '154', '155', '1550', '156', '156th', '157', '158', '159', '15a', '15am', '15mm', '15pm', '15s', '15th', '15these', '15w', '1600', '1600s', '1607', '161', '162', '163', '1632', '164', '165', '1650', '165th', '166', '1663', '167', '1670', '1678', '167th', '168', '1692', '16g', '16gb', '16mb', '16oz', '16port', '16th', '170', '1700', '171', '172', '1722', '173', '1732', '174', '175', '1750', '1751', '176', '177', '178', '1781', '1784', '1787', '1791', '1793', '17in', '17th', '1800', '1800s', '1801v', '1804', '1810', '1812', '182', '1823', '183', '184', '1841', '1843', '1849', '185', '1850', '186', '1865', '1868', '1869415', '187', '1870s', '1876', '188', '1880', '1886', '1892', '1898', '1899', '18mp', '18th', '190', '1900', '1900s', '1904', '1907', '1909', '190q', '1910', '1911', '1912', '1913', '1914', '1916', '1917', '1918', '1920', '1920s', '1921', '1922', '1924', '1925', '1926', '1928', '1929', '193', '1930', '1930s', '1933', '1937', '1938', '1939', '194', '1940', '1940s', '1941', '1943', '1945', '1947', '195', '1950', '1950s', '1951', '1953', '1954', '1955', '1956', '1957', '1958', '1959559', '195th', '1960', '1960s', '1961', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '197', '1970', '1970s', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1980s', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1990s', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '19th', '19years', '1a', '1b', '1classroom', '1e', '1i', '1kw', '1l', '1nannan', '1o', '1on1', '1pm', '1rst', '1s', '1sr', '1tb', '1th', '1ulbmve', '1x', '2000ml', '2000plus', '2000s', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '200m', '201', '2010', '2011', '2012', '2014nannan', '2016b', '2017many', '2017students', '2019', '202', '2020', '2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '203', '2030', '2031', '2033', '204', '2040', '2046', '204m', '205', '2050', '206', '207', '208', '209', '2099', '20am', '20force', '20lab', '20motion', '20net', '20s', '20x24', '20x28', '210', '2100', '2101', '2103', '2107', '211', '212', '2123', '213', '214', '215', '216', '217', '219', '21ist', '21rst', '21stcentury', '21t', '220', '2200', '221', '2219', '222', '223', '224', '225', '226', '228', '2285', '229', '22k', '22nd', '230', '2300', '231', '232', '234', '234q', '235', '2360', '237', '238', '239', '23rd', '23y', '240', '2400', '241', '242', '243', '244', '2448', '245', '246', '248', '249', '24children', '24th', '2500', '253', '254', '2550', '256', '256gb', '25920011', '25am', '25lb', '25th', '260', '2600', '262', '263', '265', '266', '267', '2683', '26th', '270', '2700', '270lbs', '273', '275', '276', '277', '278', '279', '27th', '280', '280lbs', '281', '282', '28226', '283', '286', '288', '288b', '288c', '289', '28in', '28th', '290', '291', '292', '293', '294', '296', '299', '29th', '2a', '2aa', '2chcdud', '2f', '2f151', '2fapi', '2fblog', '2fv1', '2gb', '2greve', '2having', '2i2', '2i4', '2k8', '2km', '2laptops', '2nannan', '2pm', '2s', '2small', '2st', '2x', '2x3', '2x4', '2x5', '2x6', '2xs', '2yr', '300m', '301', '302', '3023591having', '303', '30318', '304', '304bookbloggers', '305', '306', '307', '308', '3087', '309', '30am', '30hands', '30pm', '30students', '30th', '30x', '30x6', '30xa', '30xiis', '30xs', '310', '310cw', '311', '312', '3120', '313', '31313', '315', '316', '318', '319', '31st', '320', '3200', '320ish', '321', '325', '327', '328', '3288', '32g', '32gb', '32nd', '330', '3300', '334', '335', '340', '3400jc', '3404', '345', '348', '349', '3500', '355', '357', '358', '35cm', '35ft', '35mm', '3600', '360fly', '361', '363', '3637', '365', '366', '368', '369', '36x', '370', '371', '37160', '373', '374', '375', '377', '378', '37th', '380', '3800', '381', '385', '38th', '390', '392', '393', '394', '395', '397', '398', '399', '39th', '3a', '3c', '3chromebooks', '3csmart', '3d40', '3d59650', '3dimensional', '3din', '3do', '3doddler', '3doodle', '3doodlers', '3doodles', '3doodling', '3doolder', '3doolers', '3dprocess', '3ds', '3ess2', '3f', '3fuuid', '3hrs', '3k', '3lcd', '3m', '3mini', '3minutes', '3mm', '3pm', '3r', '3rds', '3rs', '3s', '3special', '3th', '3v', '3x', '3x3', '3x3x3', '3x5', '4000', '4000ish', '400i', '400m', '400th', '400x', '401', '401161546', '402', '403541', '404', '405', '408', '409stingstore', '40am', '40pm', '40s', '40th', '40x', '410', '410berrylet', '412', '415', '416', '418', '41st', '420', '421', '423', '424', '425', '426', '429', '42nd', '430', '4300', '431', '432', '438', '4392', '43k', '440', '441', '442', '445', '448', '4500', '450l', '451', '4510', '452', '4520', '453', '45300', '455', '4550', '45544', '45560', '458', '45am', '45lb', '45min', '45pm', '460', '461', '462', '465', '466', '467', '468', '469', '470', '47003', '475', '4750gs', '480', '48025', '485', '486', '487', '490', '491', '493', '495', '49th', '4a', '4c', '4creating', '4creative', '4cs', '4cscjcrkyxa', '4d', '4ft', '4g', '4gb', '4h', '4i', '4knowledge', '4m', '4o', '4pm', '4r', '4s', '4tablets', '4thgraders', '4ths', '4u', '4us', '4x', '4x5', '4x6', '4x8', '4y', '4yr', '5000', '500al', '501', '501c3', '502', '504s', '505', '506', '507', '508', '50lb', '50ml', '50mm', '50pm', '50s', '50th', '510', '514', '515', '516', '520', '523', '525', '527', '528', '529', '52nd', '530', '531', '532', '53206', '535', '536', '537', '538', '53cm', '53yrs', '540', '541', '544', '545', '546', '547', '552', '555', '557', '558', '55am', '55cm', '55in', '55mm', '560', '562', '563', '565', '5660', '570', '571', '572', '575', '576', '577', '578', '579', '580', '585', '5850', '585wi', '587', '588', '59', '590', '591', '5934', '596', '597', '598', '5a', '5am', '5as', '5c', '5d', '5e', '5ft', '5h', '5k', '5kpjngo9b9k', '5ks', '5lb', '5mil', '5my', '5pack', '5pcs', '5pm', '5protective', '5rcat', '5s', '5ss', '5t', '5x', '5x6', '5x7', '6000', '603', '605', '60k', '60min', '60s', '60th', '61', '613', '614', '61st', '61xl', '620', '6200', '6200u', '621', '622', '624', '625', '627', '628', '630', '631', '632', '634', '635', '636', '640', '645', '646', '647', '64gb', '64th', '6500', '651', '654', '655', '657', '658', '65lb', '660', '664', '665', '667', '669', '670', '675', '676', '679', '680', '681', '6830', '6830e', '685', '686', '687', '68c', '69', '690', '692', '693', '69th', '6a', '6am', '6ft', '6gb', '6i6', '6in', '6k', '6o', '6p', '6pillows', '6pm', '6the', '6ths', '6x', '6year', '6yrs', '7000', '701', '703', '705', '709', '70d', '70s', '712', '713', '717', '718', '719', '720', '720p', '721q', '722', '725', '726', '727', '728', '730', '730l', '738t', '73s', '740', '7500', '755', '75th', '760', '762', '7640', '765', '766', '770', '773', '774', '775', '777', '779', '780', '79', '792', '795', '797', '7a', '7a6', '7am', '7h', '7k', '7pm', '7quart', '7s', '7x6', '7x9', '7year', '8000', '800m', '801', '803', '808', '80min', '80s', '80th', '811', '812', '815', '818', '81st', '820', '821', '823', '825', '830', '833', '8341', '836', '83a', '840', '851', '852', '853', '8547', '856', '85a', '85th', '860', '861', '8610', '863', '865', '869', '86th', '8710', '872', '8720', '875', '877', '880', '881', '8833gry', '887', '891', '894', '8am', '8gb', '8h', '8m', '8mm', '8oz', '8s', '8t', '8threading', '8x10', '8x11', '8x24', '8x5', '9000', '905', '90min', '90mins', '90psi', '90s', '90th', '911', '912', '915', '917', '920', '920679740', '923', '925', '930', '931', '933', '935', '937', '940', '943', '947', '950', '952', '954', '956', '95th', '960', '96506742606', '967', '968', '969', '975', '97th', '980', '986', '987', '989', '990', '995', '999', '99th', '99wh', '9a', '9am', '9backgrounds', '9minutes', '9pm', '9u', '9v', '9wks', '9x12', 'a1', 'a2', 'a4872', 'a5', 'a6000', 'a8', 'aa', 'aa361', 'aa583', 'aaa', 'aaaaachhhooo', 'aaahs', 'aab', 'aac', 'aagain', 'aahhs', 'aam', 'aaopcs', 'aap', 'aappl', 'aardvark', 'aaron', 'aarp', 'aart', 'aaw', 'ab', 'aba', 'abab', 'aback', 'abacus', 'abacuses', 'abalance', 'abandon', 'abandoned', 'abandoning', 'abandonment', 'abate', 'abb', 'abbeville', 'abbott', 'abbreviations', 'abby', 'abcd', 'abcmouse', 'abcnews', 'abcs', 'abcya', 'abd', 'abdolkarim', 'abdominals', 'abe', 'abel', 'aberdeen', 'abernathy', 'abernethy', 'abi', 'abide', 'abiding', 'abigail', 'abilene', 'abiliity', 'abililty', 'abilitations', 'abilites', 'abilitiesfollowing', 'abilitiesnannan', 'abilitiesthe', 'abillities', 'abilties', 'abina', 'abingdon', 'abiotic', 'abject', 'abl', 'ablation', 'ablaze', 'abld', 'abled', 'ablenet', 'ables', 'ableton', 'ablilities', 'ablility', 'abling', 'ablities', 'abnegation', 'abnormal', 'abnormalities', 'abnormality', 'abo', 'aboard', 'abode', 'abolish', 'abolition', 'abolitionists', 'aboriginal', 'aborigines', 'abort', 'abound', 'abounding', 'abounds', 'abouts', 'abracadabra', 'abraham', 'abrasions', 'abrasive', 'abraxas', 'abrazo', 'abreast', 'abreu', 'abridged', 'abroad', 'abruptly', 'abs', 'abscesses', 'absences', 'absentee', 'absenteeism', 'absentees', 'absentes', 'absents', 'absolve', 'absorbance', 'absorbed', 'absorbent', 'absorbers', 'absorbs', 'absorption', 'abstinence', 'abstraction', 'abstractions', 'abstractly', 'abstractness', 'abstracts', 'absurd', 'abtract', 'abuela', 'abuelo', 'abulias', 'abundances', 'abundantly', 'abused', 'abuses', 'abusing', 'abusive', 'abut', 'abuzz', 'abysmally', 'abyss', 'ac', 'aca', 'acadademics', 'acadamy', 'academcially', 'academia', 'academical', 'academicallymany', 'academicallyone', 'academicallystudents', 'academicaly', 'academicly', 'academicthe', 'academicto', 'academies', 'academyguided', 'academymy', 'acadiana', 'acadmeic', 'acadmeically', 'acadmic', 'acadmics', 'accademic', 'accademically', 'accardo', 'acccess', 'accedemic', 'accelearted', 'accelerates', 'accelerating', 'acceleratiom', 'accelerations', 'accelerator', 'accelerators', 'accellerate', 'accellerated', 'accelling', 'accelorated', 'accent', 'accenting', 'accents', 'accentuate', 'accentuated', 'accentuates', 'accentuating', 'acceptances', 'acceptible', 'accepts', 'accerlerated', 'acces', 'accesibility', 'accesories', 'accessability', 'accessable', 'accessaries', 'accessecories', 'accesses', 'accessibly', 'accessorize', 'accessorized', 'accessorizing', 'accesss', 'accidental', 'accidentals', 'accidently', 'accio', 'acclaim', 'acclaimed', 'acclimate', 'acclimated', 'acclimating', 'accodomate', 'accolades', 'accom', 'accomadate', 'accomadations', 'accomidate', 'accommdate', 'accommodated', 'accommodates', 'accommodationsome', 'accomodate', 'accomodates', 'accomodating', 'accomodations', 'accompanied', 'accompanies', 'accompaniment', 'accompaniments', 'accompaning', 'accomplised', 'accomplishable', 'accomplishes', 'accord', 'accordance', 'accordin', 'accordingly', 'accordion', 'accords', 'accountant', 'accountants', 'accounted', 'accounting', 'accouterments', 'accoutrements', 'accredit', 'accreditation', 'accredited', 'accross', 'accrue', 'acculturate', 'acculturating', 'acculturation', 'accumulate', 'accumulated', 'accumulating', 'accumulation', 'accuplacer', 'accuratly', 'accusation', 'accuse', 'accused', 'accustom', 'acdemically', 'ace', 'aced', 'acedemic', 'acedemiclythe', 'acedimics', 'acedmic', 'acedmics', 'acers', 'aces', 'acess', 'acessible', 'acesss', 'acetate', 'acetone', 'acf', 'ache', 'achebe', 'acheive', 'acheivement', 'acheivements', 'acheivers', 'acheiving', 'achermannannan', 'aches', 'achieve3000', 'achievemennannan', 'achievementnannan', 'achiever', 'achieves', 'achievewe', 'achievment', 'achievments', 'achilles', 'aching', 'achitect', 'achive', 'achivement', 'achoo', 'achrome', 'achy', 'acid', 'acidification', 'acidity', 'acids', 'acing', 'acitivites', 'acitivty', 'acivities', 'ack', 'ackerman', 'ackermani', 'acknowledged', 'acknowledgement', 'acknowledgements', 'acknowledges', 'acknowledging', 'acknowledgment', 'acl', 'aclassroom', 'acls', 'aclu', 'acommodate', 'acomplish', 'acorn', 'acoste', 'acounting', 'acoustic', 'acoustical', 'acoustically', 'acoustics', 'acp', 'acpect', 'acquaint', 'acquaintance', 'acquainted', 'acquires', 'acquisitions', 'acquisitive', 'acquistion', 'acqusition', 'acre', 'acreage', 'acres', 'acrobatic', 'acronym', 'acronyms', 'acropolis', 'acrylics', 'acs', 'acsserory', 'actaually', 'acted', 'actfl', 'actice', 'acticitys', 'actidve', 'actinannan', 'actionable', 'actitivies', 'actitivites', 'actitivities', 'actitivity', 'activ', 'activatation', 'activated', 'activately', 'activates', 'activating', 'activation', 'activboard', 'activboards', 'activclassroom', 'activeboard', 'actived', 'activenannan', 'activeness', 'actives', 'activeslate', 'activetable', 'activetime', 'activexpression', 'activexpressions', 'activie', 'activies', 'activiites', 'activinspire', 'activism', 'activist', 'activists', 'activitie', 'activitiesnannan', 'activitiesthis', 'activitiy', 'activitly', 'activittuies', 'activly', 'activpanel', 'activpen', 'activslate', 'activslates', 'activtable', 'activties', 'activtities', 'activty', 'activwand', 'activwities', 'acto', 'acton', 'actor', 'actormy', 'actress', 'actresses', 'actuality', 'actualization', 'actualize', 'actualized', 'actualizing', 'actuallyican', 'actuators', 'actvf', 'actvities', 'acuity', 'acumen', 'acupressure', 'acurate', 'acute', 'acutely', 'acylic', 'acyrlic', 'ad', 'ada', 'adafruit', 'adage', 'adages', 'adah', 'adamant', 'adamantly', 'adams', 'adanced', 'adapta', 'adaptability', 'adaptation', 'adaptedmind', 'adapters', 'adaptible', 'adaption', 'adaptions', 'adaptor', 'adaptors', 'adapts', 'adc', 'addams', 'addario', 'addend', 'addends', 'addendum', 'addhd', 'addicted', 'addicting', 'addiction', 'addictions', 'addictive', 'addictiveness', 'addicts', 'addiitonal', 'addimg', 'addional', 'addision', 'addison', 'additij', 'additiona', 'additionallly', 'additionaly', 'additive', 'additives', 'additoinal', 'additon', 'additonal', 'additonally', 'addtion', 'addtional', 'addtionally', 'adductor', 'ade', 'ade95100lu', 'adel', 'ademically', 'adept', 'adeptness', 'adha', 'adhere', 'adhered', 'adherence', 'adheres', 'adhering', 'adhesive', 'adhesives', 'adichie', 'adidas', 'adiffernce', 'adirondack', 'adirondacks', 'adivina', 'adjacent', 'adjective', 'adjoining', 'adjudicated', 'adjudication', 'adjustability', 'adjuster', 'adjustment', 'adjusts', 'adl', 'adlam', 'adler', 'adlerian', 'admin', 'administer', 'administered', 'administering', 'administers', 'administrated', 'administrative', 'administrator', 'adminstration', 'admirable', 'admirably', 'admiral', 'admiration', 'admired', 'admirers', 'admiring', 'admission', 'admissions', 'admits', 'admittance', 'admitted', 'admittedly', 'admitting', 'admonish', 'admonished', 'admonishing', 'adn', 'ado', 'adobe', 'adolescants', 'adolescence', 'adolescences', 'adolescent', 'adonit', 'adopters', 'adopting', 'adoption', 'adoptions', 'adoptive', 'adopts', 'adorably', 'adored', 'adores', 'adoring', 'adorn', 'adorned', 'adorning', 'adovocate', 'adpative', 'adquisition', 'adrenal', 'adrenalin', 'adrenaline', 'adrian', 'adrift', 'ads', 'adultchild', 'adungba', 'adv', 'advancednannan', 'advanceed', 'advancenannan', 'advantaged', 'advantagemy', 'advantageous', 'advantagethis', 'advent', 'adventist', 'adventurers', 'adventuresome', 'adventuress', 'adventuring', 'adverb', 'adverbs', 'adversarial', 'adversaries', 'adversary', 'adverse', 'adversely', 'advertise', 'advertised', 'advertisement', 'advertisements', 'advertisers', 'advertising', 'advertisment', 'advice', 'advices', 'advisable', 'advise', 'advised', 'advisees', 'advisement', 'adviser', 'advises', 'advising', 'advisor', 'advisories', 'advisors', 'advnace', 'advocated', 'advocating', 'advocation', 'ae', 'aea', 'aed', 'aegean', 'aenj', 'aeramax', 'aerated', 'aeration', 'aerator', 'aere', 'aerial', 'aeries', 'aero', 'aerobic', 'aerobically', 'aerobics', 'aerocure', 'aerodynamic', 'aerodynamically', 'aerodynamics', 'aerogarden', 'aerogardening', 'aerogardens', 'aeromat', 'aeronautic', 'aeronautical', 'aeronautics', 'aerosolizes', 'aerospace', 'aeroswift', 'aes', 'aesop', 'aesthetic', 'aesthetically', 'aesthetics', 'afar', 'afb', 'afes', 'affair', 'affairs', 'affection', 'affectionally', 'affectionate', 'affectionately', 'affective', 'affectively', 'affiliate', 'affiliated', 'affiliation', 'affiliations', 'affinity', 'affirm', 'affirmation', 'affirmations', 'affirmed', 'affirming', 'affirms', 'affix', 'affixes', 'afflicted', 'afflicting', 'afflicts', 'affluence', 'affluently', 'affordability', 'affordably', 'affordestra', 'affording', 'afghan', 'afghani', 'afghanistani', 'afhd', 'aficionados', 'afield', 'afiliated', 'afloat', 'afoot', 'afore', 'aforementioned', 'africanamerican', 'africans', 'africran', 'afrikaans', 'afro', 'afrocentric', 'aft', 'afterall', 'aftercare', 'afterlife', 'aftermath', 'afterthought', 'afterward', 'afterwords', 'ag', 'again2', 'agaon', 'agape', 'agar', 'agarose', 'agassiz', 'agate', 'agatha', 'agave', 'agc', 'ageless', 'agencies', 'agenda', 'agendas', 'agent', 'agers', 'aggievision', 'aggravated', 'aggravating', 'aggravation', 'aggression', 'aggressive', 'aggressively', 'aggressiveness', 'agile', 'agilities', 'agin', 'agitated', 'agitation', 'agm', 'agnosia', 'agonizing', 'agonizingly', 'agony', 'agp', 'agr', 'agrabah', 'agreeable', 'agreeing', 'agreement', 'agreements', 'agrees', 'agression', 'agricola', 'agriculturalists', 'agriculturally', 'agriculturists', 'agriscience', 'agro', 'ags', 'agua', 'aguilar', 'ah', 'aheadmany', 'ahelp', 'ahem', 'ahern', 'ahh', 'ahha', 'ahhed', 'ahhh', 'ahhhh', 'ahhhing', 'ahhhs', 'ahhs', 'aho', 'ahold', 'ahora', 'ahoy', 'ahs', 'ahu', 'ahubhave', 'ahupua', 'ai', 'aice', 'aidan', 'aided', 'aidsl', 'aifg', 'aig', 'aija', 'aiken', 'ailer', 'ailey', 'ailing', 'ailment', 'ailments', 'ails', 'aimlessly', 'aina', 'ainissa', 'ainsworth', 'aint', 'air2', 'airborne', 'airbrush', 'airbrushed', 'airbrushing', 'aircndiners', 'aircraft', 'airdrop', 'airdropped', 'aire', 'aired']\n"
     ]
    }
   ],
   "source": [
    "print((name)[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_of_idf(data): #getting the text \n",
    "    preprocessed_text=[]\n",
    "    for text in tqdm(data):\n",
    "        words=text.split()\n",
    "        final_text=''\n",
    "        for word in words:\n",
    "            if word in name:\n",
    "                final_text+=' '+ word\n",
    "        preprocessed_text.append(final_text)\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 61176/61176 [1:35:34<00:00, 10.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61176"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_essay=text_of_idf(X_train['input_text'])\n",
    "len(X_train_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 32774/32774 [44:28<00:00, 12.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 15295/15295 [20:54<00:00, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774\n",
      "15295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_essay=text_of_idf(X_test['input_text'])\n",
    "X_cv_essay=text_of_idf(X_cv['input_text'])\n",
    "print(len(X_test_essay))\n",
    "print(len(X_cv_essay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer()\n",
    "token.fit_on_texts(X_train_essay)\n",
    "vocab_size_2=len(token.word_index) + 1\n",
    "doc1=token.texts_to_sequences(X_train_essay)\n",
    "X_train_essay=padding(doc1,max_len)\n",
    "doc2 = token.texts_to_sequences(X_cv_essay)\n",
    "X_cv_essay = padding(doc2,max_len)\n",
    "doc3 = token.texts_to_sequences(X_test_essay)\n",
    "X_test_essay = padding(doc3,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_2 = np.zeros((vocab_size_2, 300))\n",
    "for word, i in token.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix_2[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41285, 300)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embedding_matrix=embedding_matrix_2\n",
    "X_train_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 300, 300)     12385500    input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_49 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 300, 128)     219648      embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 1, 2)         104         input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 1, 2)         10          input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 1, 2)         100         input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 1, 50)        19250       input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 1, 5)         30          input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 38400)        0           lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 2)            0           embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 2)            0           embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 2)            0           embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 50)           0           embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 5)            0           embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 16)           32          input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 38477)        0           flatten_36[0][0]                 \n",
      "                                                                 flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "                                                                 flatten_41[0][0]                 \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          4925184     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 16)           2064        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2)            34          dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,552,468\n",
      "Trainable params: 5,166,712\n",
      "Non-trainable params: 12,385,756\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SpatialDropout1D, LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape\n",
    "\n",
    "input1=Input(shape=(300,))\n",
    "y1=Embedding(41285,output_dim=300,weights=[X_train_embedding_matrix],trainable=False)(input1)\n",
    "y1=LSTM(128,recurrent_dropout=0.5,kernel_regularizer=regularizers.l2(0.001),return_sequences=True)(y1)\n",
    "y1=Flatten()(y1)\n",
    "\n",
    "input2 = Input(shape=(1,))\n",
    "y2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "y2 = Flatten()(y2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "y3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "y3 = Flatten()(y3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "y4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "y4 = Flatten()(y4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "y5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "y5 = Flatten()(y5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "y6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "y6 = Flatten()(y6)\n",
    "\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "y7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#concat all inputs \n",
    "concatenate= concatenate([y1,y2,y3,y4,y5,y6,y7])\n",
    "\n",
    "x = Dense(128,kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concatenate)\n",
    "x=Dropout(0.6)(x)\n",
    "x=BatchNormalization()(x)\n",
    "x = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.6)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0003,decay = 1e-3),metrics=['accuracy',auc_roc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=ModelCheckpoint('model_2.h5',monitor='val_accuracy',save_best_only=True,mode='max')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "callbacks_2=[checkpoint,earlystop,tensorboard]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "478/478 [==============================] - 2107s 4s/step - loss: 0.7143 - accuracy: 0.7423 - auc_roc: 0.5232 - val_loss: 0.5041 - val_accuracy: 0.8486 - val_auc_roc: 0.5867\n",
      "Epoch 2/20\n",
      "478/478 [==============================] - 1251s 3s/step - loss: 0.5154 - accuracy: 0.8288 - auc_roc: 0.5416 - val_loss: 0.4504 - val_accuracy: 0.8486 - val_auc_roc: 0.6004\n",
      "Epoch 3/20\n",
      "324/478 [===================>..........] - ETA: 6:41 - loss: 0.4890 - accuracy: 0.8436 - auc_roc: 0.5443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-0f7ad1ec1f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit([X_train_essay,X_train_state,X_train_grade,X_train_cat,X_train_sub,\n\u001b[1;32m----> 2\u001b[1;33m                X_train_teacher,X_train['sum_integers']], y_train, epochs=20,verbose=1,batch_size=128,validation_data=([X_cv_essay,X_cv_state,X_cv_grade,X_cv_cat,X_cv_sub,X_cv_teacher,X_cv['sum_integers']]  , y_cv),callbacks =callbacks_2 )\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([X_train_essay,X_train_state,X_train_grade,X_train_cat,X_train_sub,\n",
    "               X_train_teacher,X_train['sum_integers']], y_train, epochs=20,verbose=1,batch_size=128,validation_data=([X_cv_essay,X_cv_state,X_cv_grade,X_cv_cat,X_cv_sub,X_cv_teacher,X_cv['sum_integers']]  , y_cv),callbacks =callbacks_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 3\n",
    "#reusing embedding of text data of model_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61176, 51) (61176, 2)\n",
      "(15295, 51) (15295, 2)\n",
      "(32774, 51) (32774, 2)\n",
      "['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc', 'de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in', 'ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn', 'mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj', 'nm', 'nv', 'ny', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx', 'ut', 'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "vector=CountVectorizer()\n",
    "vector.fit(X_train['school_state'].values)\n",
    "X_train_school_state=vector.transform(X_train['school_state'].values)\n",
    "X_cv_school_state=vector.transform(X_cv['school_state'].values)\n",
    "X_test_school_state=vector.transform(X_test['school_state'].values)\n",
    "feature_names=vector.get_feature_names()\n",
    "\n",
    "print(X_train_school_state.shape, y_train.shape)\n",
    "print(X_cv_school_state.shape, y_cv.shape)\n",
    "print(X_test_school_state.shape, y_test.shape)\n",
    "print(feature_names)\n",
    "print(\"*\" *50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61176, 5) (61176, 2)\n",
      "(15295, 5) (15295, 2)\n",
      "(32774, 5) (32774, 2)\n",
      "['dr', 'mr', 'mrs', 'ms', 'teacher']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "vector=CountVectorizer()\n",
    "vector.fit(X_train['teacher_prefix'].values)\n",
    "X_train_teacher=vector.transform(X_train['teacher_prefix'].values)\n",
    "X_cv_teacher=vector.transform(X_cv['teacher_prefix'].values)\n",
    "X_test_teacher=vector.transform(X_test['teacher_prefix'].values)\n",
    "feature_names=vector.get_feature_names()\n",
    "\n",
    "print(X_train_teacher.shape, y_train.shape)\n",
    "print(X_cv_teacher.shape, y_cv.shape)\n",
    "print(X_test_teacher.shape, y_test.shape)\n",
    "print(feature_names)\n",
    "print(\"*\" *50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61176, 4) (61176, 2)\n",
      "(15295, 4) (15295, 2)\n",
      "(32774, 4) (32774, 2)\n",
      "['grades_3_5', 'grades_6_8', 'grades_9_12', 'grades_prek_2']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "vector=CountVectorizer()\n",
    "vector.fit(X_train['project_grade_category'].values)\n",
    "X_train_grade=vector.transform(X_train['project_grade_category'].values)\n",
    "X_cv_grade=vector.transform(X_cv['project_grade_category'].values)\n",
    "X_test_grade=vector.transform(X_test['project_grade_category'].values)\n",
    "feature_names=vector.get_feature_names()\n",
    "\n",
    "print(X_train_grade.shape, y_train.shape)\n",
    "print(X_cv_grade.shape, y_cv.shape)\n",
    "print(X_test_grade.shape, y_test.shape)\n",
    "print(feature_names)\n",
    "print(\"*\" *50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61176, 9) (61176, 2)\n",
      "(15295, 9) (15295, 2)\n",
      "(32774, 9) (32774, 2)\n",
      "['appliedlearning', 'care_hunger', 'health_sports', 'history_civics', 'literacy_language', 'math_science', 'music_arts', 'specialneeds', 'warmth']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "vector=CountVectorizer()\n",
    "vector.fit(X_train['clean_categories'].values)\n",
    "X_train_cat=vector.transform(X_train['clean_categories'].values)\n",
    "X_cv_cat=vector.transform(X_cv['clean_categories'].values)\n",
    "X_test_cat=vector.transform(X_test['clean_categories'].values)\n",
    "feature_names=vector.get_feature_names()\n",
    "\n",
    "print(X_train_cat.shape, y_train.shape)\n",
    "print(X_cv_cat.shape, y_cv.shape)\n",
    "print(X_test_cat.shape, y_test.shape)\n",
    "print(feature_names)\n",
    "print(\"*\" *50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61176, 30) (61176, 2)\n",
      "(15295, 30) (15295, 2)\n",
      "(32774, 30) (32774, 2)\n",
      "['appliedsciences', 'care_hunger', 'charactereducation', 'civics_government', 'college_careerprep', 'communityservice', 'earlydevelopment', 'economics', 'environmentalscience', 'esl', 'extracurricular', 'financialliteracy', 'foreignlanguages', 'gym_fitness', 'health_lifescience', 'health_wellness', 'history_geography', 'literacy', 'literature_writing', 'mathematics', 'music', 'nutritioneducation', 'other', 'parentinvolvement', 'performingarts', 'socialsciences', 'specialneeds', 'teamsports', 'visualarts', 'warmth']\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "vector=CountVectorizer()\n",
    "vector.fit(X_train['clean_subcategories'].values)\n",
    "X_train_sub=vector.transform(X_train['clean_subcategories'].values)\n",
    "X_cv_sub=vector.transform(X_cv['clean_subcategories'].values)\n",
    "X_test_sub=vector.transform(X_test['clean_subcategories'].values)\n",
    "feature_names=vector.get_feature_names()\n",
    "\n",
    "print(X_train_sub.shape, y_train.shape)\n",
    "print(X_cv_sub.shape, y_cv.shape)\n",
    "print(X_test_sub.shape, y_test.shape)\n",
    "print(feature_names)\n",
    "print(\"*\" *50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digit = X_train['sum_integers'].values.reshape(-1,1)\n",
    "X_cv_digit = X_cv['sum_integers'].values.reshape(-1,1)\n",
    "X_test_digit = X_test['sum_integers'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "whole_train = hstack([X_train_teacher,X_train_school_state,X_train_grade,X_train_sub,X_train_cat,X_train_digit]).todense()\n",
    "whole_cv = hstack([X_cv_teacher,X_cv_school_state,X_cv_grade,X_cv_sub,X_cv_cat,X_cv_digit]).todense()\n",
    "\n",
    "X_train_3 = np.resize(whole_train,new_shape=(whole_train.shape[0],99,1))\n",
    "X_cv_3 = np.resize(whole_cv,new_shape=(whole_cv.shape[0],99,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61176, 99, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 300, 300)     14519700    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 99, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 300, 300)     0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 97, 64)       256         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 300, 256)     570368      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 95, 64)       12352       conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 76800)        0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 6080)         0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 82880)        0           flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          42435072    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 512)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          32896       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            258         leaky_re_lu_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 57,703,254\n",
      "Trainable params: 43,183,042\n",
      "Non-trainable params: 14,520,212\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# input 1\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from keras.layers import SpatialDropout1D, LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape\n",
    "from keras.layers import LeakyReLU\n",
    "input1 = Input(batch_shape=(None,300))\n",
    "x1 = Embedding(input_dim=48399,output_dim= 300,weights=[essay_matrix],trainable = False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = LSTM(256,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# input 2\n",
    "input2 = Input(shape=(99,1))\n",
    "x2 = tf.keras.layers.Conv1D(filters=64,kernel_size=3,strides=1)(input2)\n",
    "x2 = tf.keras.layers.Conv1D(filters=64,kernel_size=3,strides=1)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "# merging both the inputs\n",
    "concat = concatenate([x1,x2])\n",
    "x = Dense(512,kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.4)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(256,kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(128,kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = LeakyReLU()(x)\n",
    "# x = Dropout(0.6)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with two inputs\n",
    "model = Model([input1,input2], output)\n",
    "model.run_eagerly = True\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.adam(lr=0.0003,decay = 1e-3), metrics=['accuracy', auc_roc])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61176, 300)\n",
      "(61176, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_text.shape)\n",
    "print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61176 samples, validate on 15295 samples\n",
      "Epoch 1/50\n",
      "61176/61176 [==============================] - 1957s 32ms/sample - loss: 0.5890 - accuracy: 0.8421 - auc_roc: 0.5685 - val_loss: 0.6149 - val_accuracy: 0.8439 - val_auc_roc: 0.6524\n",
      "Epoch 2/50\n",
      "61176/61176 [==============================] - 2620s 43ms/sample - loss: 0.5088 - accuracy: 0.8480 - auc_roc: 0.6545 - val_loss: 0.5423 - val_accuracy: 0.8501 - val_auc_roc: 0.6943\n",
      "Epoch 3/50\n",
      "61176/61176 [==============================] - 3369s 55ms/sample - loss: 0.4895 - accuracy: 0.8483 - auc_roc: 0.6778 - val_loss: 0.5080 - val_accuracy: 0.8516 - val_auc_roc: 0.7036\n",
      "Epoch 4/50\n",
      "61176/61176 [==============================] - 7641s 125ms/sample - loss: 0.4813 - accuracy: 0.8489 - auc_roc: 0.6904 - val_loss: 0.5277 - val_accuracy: 0.8528 - val_auc_roc: 0.7176\n",
      "Epoch 5/50\n",
      "61176/61176 [==============================] - 5414s 88ms/sample - loss: 0.4725 - accuracy: 0.8509 - auc_roc: 0.7035 - val_loss: 0.5258 - val_accuracy: 0.8483 - val_auc_roc: 0.7172\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21a9f4e7088>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_text, X_train_3], y_train, epochs=50, verbose=1, batch_size=256, validation_data=([X_cv_text, X_cv_3]  , y_cv), callbacks = callbacks_2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61176, 50)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
