{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5050,
     "status": "ok",
     "timestamp": 1598896203000,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "ElqshAnwKCq4"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUnable to start Kernel 'gputest' due to connection timeout. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# from keras.layers import Concatenate\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Flatten, Dense,GlobalMaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5040,
     "status": "ok",
     "timestamp": 1598896203004,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "o68uJrppMd_J"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5036,
     "status": "ok",
     "timestamp": 1598896203006,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "tS6VQNd5KCrR"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "l = 40\n",
    "num_filter = 18\n",
    "compression = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qalqlZXrphVH"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18295,
     "status": "ok",
     "timestamp": 1598896216311,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "uy4-jucsKCrZ",
    "outputId": "7549d6be-2b29-4bcc-936c-fdeed7aabeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RD7UwgywKCrg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16689,
     "status": "ok",
     "timestamp": 1598896216319,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "vdnRFMfaKCrq"
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "X_train, X_test=prep_pixels(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14986,
     "status": "ok",
     "timestamp": 1598896216322,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "F3C4WUCAKCrx"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_4 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_4])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False,kernel_regularizer = regularizers.l2() ,padding='same')(relu)\n",
    "\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Pooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "\n",
    "    fc_conv=Conv2D(num_classes,kernel_size=[2,2])(Pooling)\n",
    "    output = Activation('softmax')(fc_conv)\n",
    "    flat=Flatten()(output)\n",
    "\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20899,
     "status": "ok",
     "timestamp": 1598896224182,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "9SHaug-QKCr2",
    "outputId": "01fe298f-ecd4-49c6-fc19-eb257516ab15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 36)   972         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 36)   144         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 36)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 18)   5832        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 54)   0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 54)   216         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 54)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 18)   8748        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           concatenate[0][0]                \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 72)   288         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 72)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 18)   11664       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 90)   0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 90)   360         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 90)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 18)   14580       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 108)  0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 108)  432         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 108)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 18)   17496       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 126)  0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 126)  504         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 126)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 18)   20412       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 144)  0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 144)  576         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 144)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 18)   23328       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 162)  0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 162)  648         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 162)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 18)   26244       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 180)  0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 180)  720         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 180)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 18)   29160       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 198)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 198)  792         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 198)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 18)   32076       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 216)  0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 216)  864         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 216)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 18)   34992       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 234)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 234)  936         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 234)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 18)   37908       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 252)  0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 252)  1008        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 252)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 18)   40824       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 270)  0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 270)  1080        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 270)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 18)   43740       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 288)  0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 288)  1152        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 288)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 18)   5184        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 18)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 18)   2916        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 36)   0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 36)   144         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 36)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 18)   5832        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 54)   0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 54)   216         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 54)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 18)   8748        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 72)   0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 72)   288         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 72)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 18)   11664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 90)   0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 90)   360         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 90)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 18)   14580       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 108)  0           concatenate_17[0][0]             \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 108)  432         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 108)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 18)   17496       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 126)  0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 126)  504         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 126)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 18)   20412       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 144)  0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 144)  576         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 144)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 18)   23328       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 162)  0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 162)  648         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 162)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 18)   26244       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 180)  0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 180)  720         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 180)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 18)   29160       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 198)  0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 198)  792         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 198)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 18)   32076       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 216)  0           concatenate_23[0][0]             \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 216)  864         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 216)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 18)   34992       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 234)  0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 234)  936         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 234)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 18)   37908       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 252)  0           concatenate_25[0][0]             \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 252)  1008        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 252)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 18)   40824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 270)  0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 270)  1080        concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 270)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 18)   4860        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 18)     0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 18)     72          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 18)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 18)     2916        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 18)     5832        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 54)     0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 54)     216         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 54)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 18)     8748        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 72)     0           concatenate_29[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 72)     288         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 72)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 18)     11664       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 90)     0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 90)     360         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 90)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 18)     14580       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 108)    0           concatenate_31[0][0]             \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 108)    432         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 108)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 18)     17496       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 126)    0           concatenate_32[0][0]             \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 126)    504         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 126)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 18)     20412       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 144)    0           concatenate_33[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 144)    576         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 144)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 18)     23328       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 162)    0           concatenate_34[0][0]             \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 162)    648         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 162)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 18)     26244       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 180)    0           concatenate_35[0][0]             \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 180)    720         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 180)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 18)     29160       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 8, 8, 198)    0           concatenate_36[0][0]             \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 198)    792         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 198)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 18)     32076       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 8, 8, 216)    0           concatenate_37[0][0]             \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 216)    864         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 216)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 18)     34992       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 8, 8, 234)    0           concatenate_38[0][0]             \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 234)    936         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 234)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 18)     37908       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 252)    0           concatenate_39[0][0]             \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 252)    1008        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 252)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 18)     40824       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 270)    0           concatenate_40[0][0]             \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 270)    1080        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 270)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 18)     4860        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 18)     0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 18)     72          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 18)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 18)     2916        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 36)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 36)     144         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 36)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 18)     5832        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 18)     8748        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 72)     0           concatenate_43[0][0]             \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 72)     288         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 72)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 18)     11664       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 90)     0           concatenate_44[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 90)     360         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 90)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 18)     14580       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 108)    0           concatenate_45[0][0]             \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 108)    432         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 108)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 18)     17496       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 126)    0           concatenate_46[0][0]             \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 126)    504         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 126)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 4, 4, 18)     20412       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 4, 4, 144)    0           concatenate_47[0][0]             \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 4, 144)    576         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 4, 4, 144)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 4, 4, 18)     23328       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 4, 4, 162)    0           concatenate_48[0][0]             \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 4, 4, 162)    648         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 4, 4, 162)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 4, 4, 18)     26244       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 4, 4, 180)    0           concatenate_49[0][0]             \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 180)    720         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 4, 4, 180)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 4, 4, 18)     29160       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 4, 4, 198)    0           concatenate_50[0][0]             \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 4, 4, 198)    792         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 4, 4, 198)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 4, 4, 18)     32076       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 4, 4, 216)    0           concatenate_51[0][0]             \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 4, 4, 216)    864         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 4, 4, 216)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 4, 4, 18)     34992       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 4, 4, 234)    0           concatenate_52[0][0]             \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 4, 4, 234)    936         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 4, 4, 234)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 4, 18)     37908       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 4, 4, 252)    0           concatenate_53[0][0]             \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 4, 4, 252)    1008        concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 4, 4, 252)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 18)     40824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 4, 4, 270)    0           concatenate_54[0][0]             \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 4, 4, 270)    1080        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 4, 4, 270)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 270)    0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 1, 1, 10)     10810       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1, 1, 10)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           activation_60[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,327,870\n",
      "Trainable params: 1,310,050\n",
      "Non-trainable params: 17,820\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_filter = 36\n",
    "l = 14\n",
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(36, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter)\n",
    "First_Transition = transition(First_Block, num_filter)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter)\n",
    "Second_Transition = transition(Second_Block, num_filter)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter)\n",
    "Third_Transition = transition(Third_Block, num_filter)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter)\n",
    "output=output_layer(Last_Block)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2750,
     "status": "ok",
     "timestamp": 1598896226942,
     "user": {
      "displayName": "Gaurao nandekar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBYCmY9F7zYNK_SUzjopI2qNRCk8vL4ozXVium0w=s64",
      "userId": "05140622232940681772"
     },
     "user_tz": -330
    },
    "id": "Y_rdze-rKCr7"
   },
   "outputs": [],
   "source": [
    "#determine Loss function and Optimizer\n",
    "sgd = SGD(lr=0.01, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hPDfLwQ4KCsC",
    "outputId": "404a195f-b8c4-41de-ef1e-d7f99557e17f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/299\n",
      "1563/1562 [==============================] - 302s 193ms/step - loss: 2.2041 - accuracy: 0.2609 - val_loss: 1.7722 - val_accuracy: 0.3613\n",
      "Epoch 2/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 1.8063 - accuracy: 0.3511 - val_loss: 1.6149 - val_accuracy: 0.4308\n",
      "Epoch 3/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.6635 - accuracy: 0.4093 - val_loss: 2.0754 - val_accuracy: 0.3637\n",
      "Epoch 4/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.5584 - accuracy: 0.4547 - val_loss: 1.9116 - val_accuracy: 0.4185\n",
      "Epoch 5/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 1.4551 - accuracy: 0.5039 - val_loss: 2.0680 - val_accuracy: 0.4039\n",
      "Epoch 6/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 1.3814 - accuracy: 0.5339 - val_loss: 1.8815 - val_accuracy: 0.4587\n",
      "Epoch 7/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 1.3215 - accuracy: 0.5564 - val_loss: 1.7391 - val_accuracy: 0.4632\n",
      "Epoch 8/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 1.2756 - accuracy: 0.5743 - val_loss: 1.2389 - val_accuracy: 0.6132\n",
      "Epoch 9/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 1.2257 - accuracy: 0.5936 - val_loss: 1.5012 - val_accuracy: 0.5320\n",
      "Epoch 10/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.1953 - accuracy: 0.6045 - val_loss: 1.6901 - val_accuracy: 0.5389\n",
      "Epoch 11/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.1593 - accuracy: 0.6192 - val_loss: 1.5054 - val_accuracy: 0.5895\n",
      "Epoch 12/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.1314 - accuracy: 0.6277 - val_loss: 1.5125 - val_accuracy: 0.5441\n",
      "Epoch 13/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.1029 - accuracy: 0.6411 - val_loss: 1.1774 - val_accuracy: 0.6161\n",
      "Epoch 14/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.0818 - accuracy: 0.6480 - val_loss: 1.1737 - val_accuracy: 0.6723\n",
      "Epoch 15/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.0684 - accuracy: 0.6558 - val_loss: 1.1074 - val_accuracy: 0.6675\n",
      "Epoch 16/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.0463 - accuracy: 0.6615 - val_loss: 0.7941 - val_accuracy: 0.7528\n",
      "Epoch 17/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.0203 - accuracy: 0.6732 - val_loss: 0.8230 - val_accuracy: 0.7495\n",
      "Epoch 18/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 1.0107 - accuracy: 0.6751 - val_loss: 1.0123 - val_accuracy: 0.6809\n",
      "Epoch 19/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.9816 - accuracy: 0.6862 - val_loss: 1.1725 - val_accuracy: 0.6348\n",
      "Epoch 20/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.9767 - accuracy: 0.6865 - val_loss: 1.0189 - val_accuracy: 0.6914\n",
      "Epoch 21/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.9627 - accuracy: 0.6932 - val_loss: 1.4233 - val_accuracy: 0.6287\n",
      "Epoch 22/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.9505 - accuracy: 0.7000 - val_loss: 1.2317 - val_accuracy: 0.6405\n",
      "Epoch 23/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.9417 - accuracy: 0.7010 - val_loss: 0.9983 - val_accuracy: 0.7124\n",
      "Epoch 24/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.9296 - accuracy: 0.7044 - val_loss: 0.8295 - val_accuracy: 0.7555\n",
      "Epoch 25/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.9151 - accuracy: 0.7115 - val_loss: 0.8580 - val_accuracy: 0.7337\n",
      "Epoch 26/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.9011 - accuracy: 0.7147 - val_loss: 1.1904 - val_accuracy: 0.6833\n",
      "Epoch 27/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.8908 - accuracy: 0.7179 - val_loss: 0.7485 - val_accuracy: 0.7783\n",
      "Epoch 28/299\n",
      "1563/1562 [==============================] - 299s 192ms/step - loss: 0.8783 - accuracy: 0.7221 - val_loss: 0.7228 - val_accuracy: 0.7824\n",
      "Epoch 29/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.8697 - accuracy: 0.7262 - val_loss: 0.9450 - val_accuracy: 0.7256\n",
      "Epoch 30/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.8619 - accuracy: 0.7290 - val_loss: 0.7593 - val_accuracy: 0.7744\n",
      "Epoch 31/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.8536 - accuracy: 0.7306 - val_loss: 0.8407 - val_accuracy: 0.7446\n",
      "Epoch 32/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.8447 - accuracy: 0.7338 - val_loss: 0.8630 - val_accuracy: 0.7646\n",
      "Epoch 33/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.8359 - accuracy: 0.7363 - val_loss: 0.9727 - val_accuracy: 0.7213\n",
      "Epoch 34/299\n",
      "1563/1562 [==============================] - 299s 192ms/step - loss: 0.8190 - accuracy: 0.7420 - val_loss: 0.6512 - val_accuracy: 0.8076\n",
      "Epoch 35/299\n",
      "1563/1562 [==============================] - 299s 192ms/step - loss: 0.8209 - accuracy: 0.7439 - val_loss: 0.8192 - val_accuracy: 0.7655\n",
      "Epoch 36/299\n",
      "1563/1562 [==============================] - 299s 192ms/step - loss: 0.8118 - accuracy: 0.7454 - val_loss: 0.7601 - val_accuracy: 0.7801\n",
      "Epoch 37/299\n",
      "1563/1562 [==============================] - 299s 192ms/step - loss: 0.8031 - accuracy: 0.7479 - val_loss: 0.6628 - val_accuracy: 0.8058\n",
      "Epoch 38/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.7958 - accuracy: 0.7515 - val_loss: 0.7808 - val_accuracy: 0.7756\n",
      "Epoch 39/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.7912 - accuracy: 0.7533 - val_loss: 0.9750 - val_accuracy: 0.7159\n",
      "Epoch 40/299\n",
      "1563/1562 [==============================] - 299s 192ms/step - loss: 0.7794 - accuracy: 0.7599 - val_loss: 0.5940 - val_accuracy: 0.8269\n",
      "Epoch 41/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.7783 - accuracy: 0.7575 - val_loss: 1.2775 - val_accuracy: 0.6819\n",
      "Epoch 42/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.7700 - accuracy: 0.7593 - val_loss: 0.6783 - val_accuracy: 0.8033\n",
      "Epoch 43/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.7653 - accuracy: 0.7649 - val_loss: 1.1433 - val_accuracy: 0.7022\n",
      "Epoch 44/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.7621 - accuracy: 0.7641 - val_loss: 0.6494 - val_accuracy: 0.8149\n",
      "Epoch 45/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.7541 - accuracy: 0.7656 - val_loss: 0.5514 - val_accuracy: 0.8374\n",
      "Epoch 46/299\n",
      "1563/1562 [==============================] - 299s 192ms/step - loss: 0.7441 - accuracy: 0.7685 - val_loss: 0.5476 - val_accuracy: 0.8424\n",
      "Epoch 47/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.7460 - accuracy: 0.7695 - val_loss: 0.5988 - val_accuracy: 0.8295\n",
      "Epoch 48/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.7404 - accuracy: 0.7705 - val_loss: 0.6417 - val_accuracy: 0.8051\n",
      "Epoch 49/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.7359 - accuracy: 0.7704 - val_loss: 0.6776 - val_accuracy: 0.8103\n",
      "Epoch 50/299\n",
      "1563/1562 [==============================] - 297s 190ms/step - loss: 0.7246 - accuracy: 0.7741 - val_loss: 0.6967 - val_accuracy: 0.7955\n",
      "Epoch 51/299\n",
      "1563/1562 [==============================] - 297s 190ms/step - loss: 0.7210 - accuracy: 0.7753 - val_loss: 0.5883 - val_accuracy: 0.8293\n",
      "Epoch 52/299\n",
      "1563/1562 [==============================] - 297s 190ms/step - loss: 0.7214 - accuracy: 0.7749 - val_loss: 0.7513 - val_accuracy: 0.7944\n",
      "Epoch 53/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.7080 - accuracy: 0.7801 - val_loss: 0.7105 - val_accuracy: 0.7991\n",
      "Epoch 54/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.7080 - accuracy: 0.7819 - val_loss: 0.8281 - val_accuracy: 0.7769\n",
      "Epoch 55/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.7012 - accuracy: 0.7822 - val_loss: 0.5524 - val_accuracy: 0.8412\n",
      "Epoch 56/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6955 - accuracy: 0.7857 - val_loss: 0.5586 - val_accuracy: 0.8386\n",
      "Epoch 57/299\n",
      "1563/1562 [==============================] - 298s 190ms/step - loss: 0.6913 - accuracy: 0.7856 - val_loss: 0.8307 - val_accuracy: 0.7796\n",
      "Epoch 58/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6922 - accuracy: 0.7870 - val_loss: 0.5319 - val_accuracy: 0.8480\n",
      "Epoch 59/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6895 - accuracy: 0.7859 - val_loss: 0.9745 - val_accuracy: 0.7289\n",
      "Epoch 60/299\n",
      "1563/1562 [==============================] - 298s 190ms/step - loss: 0.6858 - accuracy: 0.7878 - val_loss: 0.5752 - val_accuracy: 0.8357\n",
      "Epoch 61/299\n",
      "1563/1562 [==============================] - 297s 190ms/step - loss: 0.6753 - accuracy: 0.7913 - val_loss: 0.6229 - val_accuracy: 0.8251\n",
      "Epoch 62/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6690 - accuracy: 0.7921 - val_loss: 0.7921 - val_accuracy: 0.7897\n",
      "Epoch 63/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6720 - accuracy: 0.7923 - val_loss: 0.6613 - val_accuracy: 0.8099\n",
      "Epoch 64/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.6609 - accuracy: 0.7943 - val_loss: 0.5656 - val_accuracy: 0.8384\n",
      "Epoch 65/299\n",
      "1563/1562 [==============================] - 300s 192ms/step - loss: 0.6629 - accuracy: 0.7970 - val_loss: 0.5239 - val_accuracy: 0.8537\n",
      "Epoch 66/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.6578 - accuracy: 0.7958 - val_loss: 0.4915 - val_accuracy: 0.8574\n",
      "Epoch 67/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.6491 - accuracy: 0.7991 - val_loss: 0.5230 - val_accuracy: 0.8572\n",
      "Epoch 68/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6534 - accuracy: 0.7978 - val_loss: 0.4962 - val_accuracy: 0.8542\n",
      "Epoch 69/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6483 - accuracy: 0.7989 - val_loss: 0.6870 - val_accuracy: 0.8142\n",
      "Epoch 70/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6396 - accuracy: 0.8025 - val_loss: 0.4972 - val_accuracy: 0.8638\n",
      "Epoch 71/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6429 - accuracy: 0.8015 - val_loss: 0.4761 - val_accuracy: 0.8650\n",
      "Epoch 72/299\n",
      "1563/1562 [==============================] - 297s 190ms/step - loss: 0.6327 - accuracy: 0.8060 - val_loss: 0.6126 - val_accuracy: 0.8355\n",
      "Epoch 73/299\n",
      "1563/1562 [==============================] - 297s 190ms/step - loss: 0.6342 - accuracy: 0.8031 - val_loss: 0.6111 - val_accuracy: 0.8304\n",
      "Epoch 74/299\n",
      "1563/1562 [==============================] - 297s 190ms/step - loss: 0.6334 - accuracy: 0.8059 - val_loss: 0.7103 - val_accuracy: 0.8066\n",
      "Epoch 75/299\n",
      "1563/1562 [==============================] - 298s 190ms/step - loss: 0.6277 - accuracy: 0.8054 - val_loss: 0.4605 - val_accuracy: 0.8725\n",
      "Epoch 76/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6261 - accuracy: 0.8076 - val_loss: 0.5222 - val_accuracy: 0.8560\n",
      "Epoch 77/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.6159 - accuracy: 0.8098 - val_loss: 0.5597 - val_accuracy: 0.8451\n",
      "Epoch 78/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6175 - accuracy: 0.8088 - val_loss: 0.5026 - val_accuracy: 0.8637\n",
      "Epoch 79/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6152 - accuracy: 0.8123 - val_loss: 0.5424 - val_accuracy: 0.8496\n",
      "Epoch 80/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6146 - accuracy: 0.8097 - val_loss: 0.5184 - val_accuracy: 0.8562\n",
      "Epoch 81/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6097 - accuracy: 0.8120 - val_loss: 0.7097 - val_accuracy: 0.8133\n",
      "Epoch 82/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.6144 - accuracy: 0.8099 - val_loss: 0.5133 - val_accuracy: 0.8566\n",
      "Epoch 83/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.6042 - accuracy: 0.8141 - val_loss: 0.5510 - val_accuracy: 0.8439\n",
      "Epoch 84/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.6057 - accuracy: 0.8143 - val_loss: 0.5799 - val_accuracy: 0.8430\n",
      "Epoch 85/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.5984 - accuracy: 0.8150 - val_loss: 0.5001 - val_accuracy: 0.8587\n",
      "Epoch 86/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.6017 - accuracy: 0.8131 - val_loss: 0.5730 - val_accuracy: 0.8422\n",
      "Epoch 87/299\n",
      "1563/1562 [==============================] - 299s 191ms/step - loss: 0.5931 - accuracy: 0.8163 - val_loss: 0.5703 - val_accuracy: 0.8407\n",
      "Epoch 88/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.5894 - accuracy: 0.8183 - val_loss: 0.4984 - val_accuracy: 0.8625\n",
      "Epoch 89/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.5918 - accuracy: 0.8170 - val_loss: 0.6422 - val_accuracy: 0.8218\n",
      "Epoch 90/299\n",
      "1563/1562 [==============================] - 298s 191ms/step - loss: 0.5914 - accuracy: 0.8162 - val_loss: 0.4828 - val_accuracy: 0.8650\n",
      "Epoch 91/299\n",
      "1563/1562 [==============================] - 298s 190ms/step - loss: 0.5843 - accuracy: 0.8193 - val_loss: 0.4784 - val_accuracy: 0.8636\n",
      "Epoch 92/299\n",
      "1080/1562 [===================>..........] - ETA: 1:27 - loss: 0.5830 - accuracy: 0.8194"
     ]
    }
   ],
   "source": [
    "img = ImageDataGenerator(width_shift_range=0.5,rotation_range=15, height_shift_range=0.5,shear_range=0.2,horizontal_flip=True,zoom_range=0.2)\n",
    "img.fit(X_train)\n",
    "train_gen = img.flow(X_train, y_train,batch_size=32,shuffle=True)\n",
    "history = model.fit(train_gen,steps_per_epoch=X_train.shape[0]/32,epochs=299, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsPpSz5IKCsI"
   },
   "outputs": [],
   "source": [
    "history.save_weights(os.path.join(path, 'first_30_epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYE29KFNKCsP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5Z7VvQFKCsV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLit9PPhKCsc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_CIFR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
